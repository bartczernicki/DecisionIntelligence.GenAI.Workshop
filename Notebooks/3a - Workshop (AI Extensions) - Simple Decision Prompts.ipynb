{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"display: flex; align-items: center;\">\n",
        "  <img src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/SemanticKernelLogo.png\" width=\"40px\" style=\"margin-right: 10px;\">\n",
        "  <span style=\"font-size: 1.5em; font-weight: bold;\">3a - Workshop (AI Extensions) - Simple Decision Prompts</span>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decision Intelligence concepts applied in this module:  \n",
        "* Listing generic decision-making tools trained-into Generative AI LLMs   \n",
        "* Creating custom AI personas with a system decision prompt  \n",
        "* Generating decision outputs using easier to consume formats (Markdown)     \n",
        "\n",
        "Prompts are the fundamental building blocks for eliciting effective responses from AI models. This module demonstrates how to use common prompt engineering techniques within Microsoft AI Extensions. If you‚Äôve used ChatGPT or Microsoft Copilot, you‚Äôre already familiar with prompting: given an instruction, a language model predicts the most likely and relevant response. With Microsoft AI Extensions, you can build applications, services, and APIs that execute these prompts quickly and effectively. \n",
        "\n",
        "For more information on using prompts with Microsoft Extensions AI, visit: https://learn.microsoft.com/en-us/dotnet/ai/quickstarts/prompt-model?pivots=azure-openai \n",
        "\n",
        "The process of carefully crafting questions or instructions for AI is called **Prompt Engineering**. Prompt Engineering involves designing and refining input prompts‚Äîtext or questions‚Äîso that the AI produces responses that are more relevant, useful, or accurate. The goal is to maximize the quality and clarity of the AI‚Äôs output, often by using specific wording, added context, or concrete examples within the prompt. \n",
        "\n",
        "> üìù **Note:** Future modules will evolve the prompts to include **Context Engineering**, which is a more broader technique that includes setting up an information architecture (memory, exeternal data, system prompts, MCP Tools etc.) for making better decisions. \n",
        "\n",
        "By combining Decision Intelligence with Prompt Engineering/Context Engineering, you can create **‚ÄúDecision Intelligence powered by Generative AI‚Äù**. This approach leverages Generative AI models to apply decision-making pricingples, by reasoning through complex decision scenarios, gathering intelligence, recommending decisions, and communicating results more effectively. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 1 - Initialize Configuration Builder & Build the AI Orchestration "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the next two cells to:\n",
        "* Use the Configuration Builder to load the API secrets.  \n",
        "* Use the API configuration to build the AI orchestrator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 10.0.1</span></li><li><span>Microsoft.Extensions.Configuration.Json, 10.0.1</span></li><li><span>System.Text.Json, 10.0.1</span></li></ul></div></div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "// Import the required NuGet configuration packages\n",
        "#r \"nuget: Microsoft.Extensions.Configuration, 10.0.1\"\n",
        "#r \"nuget: Microsoft.Extensions.Configuration.Json, 10.0.1\"\n",
        "#r \"nuget: System.Text.Json, 10.0.1\"\n",
        "\n",
        "using Microsoft.Extensions.Configuration.Json;\n",
        "using Microsoft.Extensions.Configuration;\n",
        "using System.IO;\n",
        "using System;\n",
        "\n",
        "// Load the configuration settings from the local.settings.json and secrets.settings.json files\n",
        "// The secrets.settings.json file is used to store sensitive information such as API keys\n",
        "var configurationBuilder = new ConfigurationBuilder()\n",
        "    .SetBasePath(Directory.GetCurrentDirectory())\n",
        "    .AddJsonFile(\"local.settings.json\", optional: true, reloadOnChange: true)\n",
        "    .AddJsonFile(\"secrets.settings.json\", optional: true, reloadOnChange: true);\n",
        "var config = configurationBuilder.Build();\n",
        "\n",
        "// IMPORTANT: You ONLY NEED either Azure OpenAI or OpenAI connection info, not both.\n",
        "// Azure OpenAI Connection Info\n",
        "var azureOpenAIEndpoint = config[\"AzureOpenAI:Endpoint\"];\n",
        "var azureOpenAIAPIKey = config[\"AzureOpenAI:APIKey\"];\n",
        "var azureOpenAIModelDeploymentName = config[\"AzureOpenAI:ModelDeploymentName\"];\n",
        "// OpenAI Connection Info \n",
        "var openAIAPIKey = config[\"OpenAI:APIKey\"];\n",
        "var openAIModelId = config[\"OpenAI:ModelId\"];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 2.8.0-beta.1</span></li><li><span>Azure.Identity, 1.18.0-beta.2</span></li><li><span>Microsoft.Extensions.AI, 10.1.1</span></li><li><span>Microsoft.Extensions.AI.Abstractions, 10.1.1</span></li><li><span>Microsoft.Extensions.AI.OpenAI, 10.1.1-preview.1.25612.2</span></li><li><span>OpenAI, 2.8.0</span></li></ul></div></div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Azure OpenAI Service\n"
          ]
        }
      ],
      "source": [
        "// Import the Microdoft Extensions AI NuGet Packages\n",
        "#r \"nuget: Microsoft.Extensions.AI, 10.1.1\"\n",
        "#r \"nuget: Microsoft.Extensions.AI.Abstractions, 10.1.1\"\n",
        "#r \"nuget: Microsoft.Extensions.AI.OpenAI, 10.1.1-preview.1.25612.2\"\n",
        "// Import Azure & OpenAI NuGet Packages\n",
        "#r \"nuget: Azure.AI.OpenAI, 2.8.0-beta.1\"\n",
        "#r \"nuget: Azure.Identity, 1.18.0-beta.2\"\n",
        "#r \"nuget: OpenAI, 2.8.0\"\n",
        "\n",
        "using Azure;\n",
        "using Azure.AI.OpenAI;\n",
        "using Microsoft.Extensions.AI;\n",
        "using Microsoft.Extensions.Configuration;\n",
        "using OpenAI.Chat;\n",
        "using System.ClientModel;\n",
        "using System.ComponentModel;\n",
        "using System.Text.Json;\n",
        "\n",
        "// Set the flag to use Azure OpenAI or OpenAI. False to use OpenAI, True to use Azure OpenAI\n",
        "var useAzureOpenAI = true;\n",
        "IChatClient chatClient;\n",
        "\n",
        "// Create a new Semantic Kernel instance\n",
        "if (useAzureOpenAI)\n",
        "{\n",
        "    Console.WriteLine(\"Using Azure OpenAI Service\");\n",
        "\n",
        "    var apiKeyCredential = new ApiKeyCredential(azureOpenAIAPIKey);\n",
        "    var azureOpenAIClient = new AzureOpenAIClient(new Uri(azureOpenAIEndpoint), apiKeyCredential);\n",
        "\n",
        "    #pragma warning disable OPENAI001\n",
        "    chatClient = azureOpenAIClient.GetChatClient(azureOpenAIModelDeploymentName).AsIChatClient();\n",
        "}\n",
        "else\n",
        "{\n",
        "    Console.WriteLine(\"Using OpenAI Service\");\n",
        "\n",
        "    var apiKeyCredential = new ApiKeyCredential(azureOpenAIAPIKey);\n",
        "    var azureOpenAIClient = new AzureOpenAIClient(new Uri(azureOpenAIEndpoint), apiKeyCredential);\n",
        "\n",
        "    #pragma warning disable OPENAI001\n",
        "    chatClient = azureOpenAIClient.GetChatClient(azureOpenAIModelDeploymentName).AsIChatClient();\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 2 - Execute a Decision Prompt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Many LLMs and even SLMs have been trained on knowledge that includes decision frameworks & processes. This makes LLMs great decision assistants, which can:\n",
        "* Provide proper Decision Frames \n",
        "* Gather Intelligence (information) in order to make a decision\n",
        "* Recommend Decision Frameworks to make a high-quality decision\n",
        "* Provide feedback to evaluate a Decision\n",
        "\n",
        "Once the chat client instance is instantiated, it is ready to intake prompt instructions. In the prompt below, the chat client object is instructed to provide examples of decision frameworks \"trained into\" the knowledge of the configured AI model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are **five decision-making frameworks** and how each can support better analysis and reasoning:  \n",
            "\n",
            "---\n",
            "\n",
            "**1. OODA Loop (Observe ‚Äì Orient ‚Äì Decide ‚Äì Act)**  \n",
            "- **Description:** Originally developed for military strategy, this iterative process involves observing the situation, orienting by analyzing the context, deciding on a course of action, and acting before repeating the cycle.  \n",
            "- **Benefit:** It promotes rapid assessment and adjustment, helping decision-makers respond effectively in dynamic or uncertain environments such as crisis management or competitive markets.\n",
            "\n",
            "---\n",
            "\n",
            "**2. SWOT Analysis (Strengths ‚Äì Weaknesses ‚Äì Opportunities ‚Äì Threats)**  \n",
            "- **Description:** An analytical tool that categorizes internal strengths and weaknesses, and external opportunities and threats, to understand the strategic position.  \n",
            "- **Benefit:** It encourages a balanced view that factors in both internal capabilities and external influences, helping to make more informed strategic or operational choices.\n",
            "\n",
            "---\n",
            "\n",
            "**3. Cost-Benefit Analysis (CBA)**  \n",
            "- **Description:** A quantitative approach that compares the expected costs and benefits of each decision option, often translated into monetary terms where possible.  \n",
            "- **Benefit:** It supports rational decision-making by making trade-offs clearer and grounding judgments in measurable outcomes.\n",
            "\n",
            "---\n",
            "\n",
            "**4. Decision Matrix (Weighted Scoring Model)**  \n",
            "- **Description:** This involves listing decision criteria, assigning weights according to importance, scoring each option against these criteria, and calculating a weighted score.  \n",
            "- **Benefit:** It brings structure and transparency to complex multi-criteria decisions, ensuring that the most important factors carry the most influence.\n",
            "\n",
            "---\n",
            "\n",
            "**5. Six Thinking Hats (Edward de Bono)**  \n",
            "- **Description:** A parallel thinking method that assigns different ‚Äúhats‚Äù to modes of thinking‚Äîfacts, feelings, caution, optimism, creativity, and process‚Äîto explore a decision from multiple angles.  \n",
            "- **Benefit:** It reduces groupthink, ensures well-rounded analysis, and encourages participants to consider all perspectives before deciding.\n",
            "\n",
            "---\n",
            "\n",
            "If you‚Äôd like, I can also prepare a **comparison table** showing when each framework is most effective. Would you like me to create that?\n"
          ]
        }
      ],
      "source": [
        "using System.Text.Json;\n",
        "\n",
        "// A simple Decision Intelligence prompt to help with describing decision-making frameworks\n",
        "var simpleDecisionPrompt = \"\"\"\n",
        "Identify and list 5 decision-making frameworks that can enhance the quality of decisions. \n",
        "Briefly describe how each decision-making framework supports better analysis and reasoning in various scenarios. \n",
        "\"\"\";\n",
        "\n",
        "// Execute the prompt against the AI model\n",
        "var simplePromptResponse = await chatClient.GetResponseAsync(simpleDecisionPrompt);\n",
        "var responseString = simplePromptResponse.Messages[0].Contents[0].ToString();\n",
        "\n",
        "// Display the response from the AI model\n",
        "Console.WriteLine(responseString);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 3 - Execute a Decision Prompt with Streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Microsoft AI Extensions chat clients support response streaming when invoking the prompt. This allows responses to be streamed to the console as soon as they are made available by the LLM and service. Below the same decision prompt executed in Step 2 is used. However, notice that chunks are streamed and can be read by the user as soon as they are available. \n",
        "\n",
        "> üìù **Note:** An average human can read between 25-40 Tokens / second. Therefore, while streaming certainly helps with providing AI output to the user, it begins to lose its effectiveness at large token velocity. Furthermore, while streaming certainly shows a responsive system, it does lose its effectiveness when the AI system needs to perform long processing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are **five decision-making frameworks** and how they can improve analysis and reasoning:\n",
            "\n",
            "---\n",
            "\n",
            "**1. SWOT Analysis (Strengths, Weaknesses, Opportunities, Threats)**  \n",
            "- **Description:** A structured method for evaluating internal strengths and weaknesses, along with external opportunities and threats.  \n",
            "- **How it helps:** By categorizing factors into these four quadrants, decision-makers get a balanced view of what can help or hinder success. It ensures that internal capabilities and external environmental factors are both considered, promoting more informed and strategic choices.\n",
            "\n",
            "---\n",
            "\n",
            "**2. Cost-Benefit Analysis (CBA)**  \n",
            "- **Description:** A quantitative approach that compares the total expected costs of a decision to its anticipated benefits, often expressed in monetary terms.  \n",
            "- **How it helps:** Provides a clear economic rationale for choices, helps prioritize options with the greatest net gain, and allows for transparent stakeholder communication regarding why a decision is financially sound.\n",
            "\n",
            "---\n",
            "\n",
            "**3. Decision Matrix (Weighted Scoring Model)**  \n",
            "- **Description:** A tabular method where decision criteria are assigned weightings, and each option is scored against those criteria.  \n",
            "- **How it helps:** Supports objective, side-by-side comparison of multiple alternatives. Helps avoid bias by quantifying subjective preferences and making trade-offs explicit.\n",
            "\n",
            "---\n",
            "\n",
            "**4. OODA Loop (Observe ‚Äì Orient ‚Äì Decide ‚Äì Act)**  \n",
            "- **Description:** A cyclical, adaptive decision process originating from military strategy but applicable in business and other fast-changing environments.  \n",
            "- **How it helps:** Encourages continuous learning and adaptation, ensuring decisions are based on the most current information and that actions can be recalibrated quickly when conditions change.\n",
            "\n",
            "---\n",
            "\n",
            "**5. Six Thinking Hats (Edward de Bono)**  \n",
            "- **Description:** A parallel thinking process where participants adopt different \"hats\" representing distinct perspective types (e.g., logical, emotional, creative, risk-focused).  \n",
            "- **How it helps:** Encourages examination of a problem from multiple angles, reduces groupthink, and facilitates balanced reasoning that incorporates facts, creativity, caution, and optimism.\n",
            "\n",
            "---\n",
            "\n",
            "If you‚Äôd like, I can also **compare these frameworks side-by-side** to help you decide which is most suitable for a particular decision context. Would you like me to create that comparison table?"
          ]
        }
      ],
      "source": [
        "// Same Decision Intelligence prompt executed using Streaming output chunks \n",
        "await foreach (var streamChunk in chatClient.GetStreamingResponseAsync(simpleDecisionPrompt))\n",
        "{\n",
        "   Console.Write(streamChunk);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 4 - Execute a Decision Prompt with Improved Output Formatting  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generative AI models have an inherent ability to not only provide decision reasoning analysis, but also format the output in a desired format. This could be as simple as instructing the Generative AI model to format the decision as a single sentence, paragraphs or lists. However more sophisticated output generations can be instructed. For example, the GenAI model can output Markdown or even extract information and fill in a desired schema (JSON). Specifically for Decision Intelligence, you can ask the GenAI models to apply decision communication frameworks to the generation as well. \n",
        "\n",
        "Execute the simple decision prompt below with Markdown formatting output. This table can now be rendered in a Markdown document for easy human comprehension. Markdown tables and other formats can be used on web sites, document, programming code etc. Even Generative AI models understand Markdown format, which can not only be used for output but inside input prompts.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "| Decision-Making Framework | Description | How It Enhances Analysis and Reasoning |\n",
              "|---------------------------|-------------|-----------------------------------------|\n",
              "| SWOT Analysis | Identifies internal Strengths and Weaknesses, and external Opportunities and Threats. | Encourages a balanced view by assessing both internal capabilities and external factors, leading to more informed and strategic decisions. |\n",
              "| Cost-Benefit Analysis (CBA) | Compares the projected costs and benefits of a decision. | Provides a quantitative basis for comparing alternatives, improving objectivity and minimizing emotional bias. |\n",
              "| OODA Loop (Observe, Orient, Decide, Act) | Iterative cycle for rapid decision-making and adaptation. | Promotes continuous reassessment and adaptability, which is critical in fast-changing environments. |\n",
              "| Decision Matrix | Scores and ranks options based on weighted criteria. | Helps prioritize alternatives according to defined, transparent criteria, reducing subjectivity in selection. |\n",
              "| Six Thinking Hats | Uses six distinct thinking modes to assess a problem from multiple perspectives. | Encourages comprehensive exploration of facts, risks, creativity, and emotions, leading to well-rounded and less biased decisions. |"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "// A new decision prompt to help with describing decision-making frameworks using table Markdown format\n",
        "var simpleDecisionPromptWithMarkdownFormat = \"\"\"\n",
        "Identify and list 5 decision-making frameworks that can enhance the quality of decisions. \n",
        "Briefly describe how each decision-making framework supports better analysis and reasoning in various scenarios.\n",
        "\n",
        "Format the response using only a Markdown table. Only return a Markdown table. \n",
        "Do not enclose the table in triple backticks.\n",
        "\"\"\";\n",
        "\n",
        "// Execute the prompt against the AI model\n",
        "var simplePromptResponseWithMarkdownFormat = await chatClient.GetResponseAsync(simpleDecisionPromptWithMarkdownFormat);\n",
        "var responseStringWithMarkdownFormat = simplePromptResponseWithMarkdownFormat.Messages[0].Contents[0].ToString();\n",
        "\n",
        "// Display the response from the Semantic Kernel as Markdown\n",
        "responseStringWithMarkdownFormat.DisplayAs(\"text/markdown\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 5 - Execute a Decision Prompt with a Custom Prompt Execution Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Microsoft AI clients support the configuration of prompt execution. The typical OpenAI and Azure OpenAI settings are exposed as configuration options that provide a different AI output experience. Non-reasoning models GPT-3.5 through GPT4.1 support settings like Temperature, LogProbs, TopK to optimize returns. Most recently (in the year 2026), most top performing Generative AI models are reasoning models, which simplify the configuration to reasoning effort (Minimal, Low, Medium, High) or token thinking budgets. This basically is a reasoning setting that correlates to how many resources the AI models spend \"thinking\" (internal monologue) before the AI executes the prompt instructions. \n",
        "\n",
        "> **üìù Note:** The supported prompt settings are dependent on the API plus the specific model version. For example, an AI model paired with an older API may not expose all the configuration settings available. Conversely, a new preview model may not have all the settings available until it becomes generally available. Types of model execution (general versus reasoning) will also have different execution setting parameters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the code cell below. Note there is a new ChatOptions object instantiated that specifies how we would like the AI to process the decision intelligence prompt. Note two key changes:\n",
        "* **MaxOutputTokens** setting is set at 100, which will set a maximum of tokens allowed for the AI model to output\n",
        "* **ResponseFormat** setting is set to JSON, which will return the response in a structured JSON object. An optional JSON schema can be supplied to enforce output in more specific ways.  \n",
        "\n",
        "Notice the output difference below is greatly truncated, try changing MaxOutputTokens to a higher value and re-run. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"decision_making_frameworks\": [\n",
            "    {\n",
            "      \"name\": \"SWOT Analysis\",\n",
            "      \"description\": \"SWOT (Strengths, Weaknesses, Opportunities, Threats) Analysis helps in evaluating internal and external factors influencing a decision. By organizing insights into these four categories, decision-makers can better assess trade-offs and strategic alignments.\",\n",
            "      \"benefit\": \"Supports strategic thinking by balancing internal capabilities with external possibilities and risks.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\":\n"
          ]
        }
      ],
      "source": [
        "// Declare new chat options setting MaxOutputTokens and ResponseFormat to JSON explicitly\n",
        "var chatOptions = new ChatOptions\n",
        "{\n",
        "    MaxOutputTokens = 100,\n",
        "    ResponseFormat = Microsoft.Extensions.AI.ChatResponseFormat.Json\n",
        "};\n",
        "\n",
        "var simpleDecisionPromptWithJsonFormat = \"\"\"\n",
        "Identify and list 5 decision-making frameworks that can enhance the quality of decisions. \n",
        "Briefly describe how each decision-making framework supports better analysis and reasoning in various scenarios.\n",
        "\n",
        "Return the response in JSON format. \n",
        "\"\"\";\n",
        "\n",
        "// Execute the prompt against the AI model, pass in the chat options settings\n",
        "var simplePromptResponse = await chatClient.GetResponseAsync(simpleDecisionPromptWithJsonFormat, chatOptions);\n",
        "var responseString = simplePromptResponse.Messages[0].Contents[0].ToString();\n",
        "\n",
        "// Display the response from the Semantic Kernel as Markdown\n",
        "Console.WriteLine(responseString);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 6 - Execute a Decision Prompt with a System Prompt (Custom AI Persona)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When building Decision Intelligence prompts, the typical best practices of prompt engineering apply. \n",
        "\n",
        "This includes: \n",
        "* Make the prompt more specific (i.e. decision intelligence)\n",
        "* Add desired structure to the output with formatting\n",
        "* Provide examples with few-shot prompting \n",
        "* Instruct the AI what to do to avoid doing something else\n",
        "* Provide context (additional information) to the AI\n",
        "* Using Roles in Chat Completion API prompts\n",
        "* Give your AI words of encouragement  \n",
        "* Cleanly dillineate sections in complex prompts \n",
        "\n",
        "A fundemental prompting best practice is to provide a common behavior across all the LLM interactions in a system prompt. The system prompt is passed in on every single call to the AI model. By passing the same (or similar) system prompt with every prompt gives your Generative AI system a common behavior across all your decision framework needs. This can be thought of as a **\"persona\"**. Furthermore, this common persona is the foundational building block of building AI agents; where the desired behavior is to have each agent have a unique persona/behavior every time you interact with that agent.  \n",
        "\n",
        "\n",
        "The core idea of a system prompt is to group all of common decision tasks, formats, decision approaches and place all of those things into the system prompt that can be re-used over and over for all of your prompt instructions & agentic subsequent calls. \n",
        "\n",
        "Execute the code cell below with a dynamic system prompt and prompt instructions. Notice the different behavior of the output for decision frameworks. Based on the new system prompt, the decision-making responses can be much more aligned with the provided decision intelligence information. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": []
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "// Create a System Prompt instruction to override the default system prompt\n",
        "// Add the System Prompt (Persona) to behave like a Decision Intelligence assistant\n",
        "var systemPromptForDecisions = \"\"\"\n",
        "You are a Decision Intelligence Assistant. \n",
        "Assist the user in exploring options, reasoning through decisions, problem-solving.\n",
        "Apply systems thinking to the scenarios. \n",
        "Provide structured, logical, and comprehensive decision advice.\n",
        "\n",
        "Output Format Instructions: \n",
        "When generating Markdown, do not use any headings higher than ###. \n",
        "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
        "All top-level section headers should start at ### or lower. \n",
        "Never use ---, ***, or ___ for horizontal lines. There should be no horizontal lines in the output.\n",
        "For separation, use extra extra spacing. Do not any render horizontal lines.\n",
        "\n",
        "Format the response using only a Markdown table. Only return a Markdown table. \n",
        "Do not enclose the table in triple backticks.\n",
        "\"\"\";\n",
        "\n",
        "var simpleDecisionPrompt = \"\"\"\n",
        "Recommend the top 5 decision frameworks that can be used for daily situations to make various decisions.\n",
        "These frameworks should be very easy to understand and apply to various scenarios.\n",
        "\"\"\";\n",
        "\n",
        "// How the prompt looks like to the LLM\n",
        "var simpleDecisionPromptTemplate = $\"\"\"\n",
        "System Prompt: \n",
        "{systemPromptForDecisions}\n",
        "\n",
        "Request from the user: \n",
        "{simpleDecisionPrompt}\n",
        "\"\"\";\n",
        "\n",
        "PromptExecutionSettings promptExecutionSettings = new();\n",
        "\n",
        "if (useAzureOpenAI)\n",
        "{\n",
        "    // Create a new Azure OpenAI Prompt Execution settings object\n",
        "    #pragma warning disable SKEXP0010\n",
        "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
        "        SetNewMaxCompletionTokensEnabled = true,\n",
        "        MaxTokens = 1500,\n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "else\n",
        "{\n",
        "    // Create a new OpenAI Prompt Execution settings object\n",
        "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "// Create a new KernelArguments object with the AzureOpenAI / OpenAI prompt execution settings\n",
        "KernelArguments kernelArguments = new KernelArguments(promptExecutionSettings);\n",
        "\n",
        "\n",
        "var promptResponseWithTemplate = await semanticKernel.InvokePromptAsync(simpleDecisionPrompt, kernelArguments);\n",
        "var response = promptResponseWithTemplate.GetValue<string>();\n",
        "\n",
        "// Display the response from the Semantic Kernel as Markdown\n",
        "response.DisplayAs(\"text/markdown\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 7 - Execute a Decision Scenario with a System Prompt (Custom AI Persona)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this step a decision scenario will be introduced requiring analysis and a recommendation performed by Artificial Intelligence. The full **Decision Intelligence** framework will not be used, rather a simple request for Artificial Intelligence to recommend a path forward (recommendation) for the human user to ultimately make the final decision.  \n",
        "\n",
        "**Decision Scenario:** Your high school daughter Alex is deciding whether to enroll directly in a four-year university or start at a community college to earn an associate degree first. These are Alex's main decision factors: financial, career uncertainty, academic consistency and future impact. In addition, you have all the decision factor detailed data available to pass to the GenAI model prompt. You are looking for an impartial (non-family) recommendation. Can Artificial Intelligence be that impartial judge to help Alex decide? \n",
        "\n",
        "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-SimpleDecision-College.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### Recommendation\n",
              "\n",
              "| Recommendation | Why (concise rationale) | Key trade-offs (most important) | Concrete next steps (first 12 months) | Contingencies / when to change course |\n",
              "|---|---:|---|---|---|\n",
              "| Start at the community college with an intentional, transfer-focused plan to a well-regarded four‚Äëyear university after 1‚Äì2 years. | Saves substantial money while giving Alex low‚Äërisk space to explore majors (business, psychology, arts) and avoid costly major-switching at the expensive four‚Äëyear; preserve ability to transfer later to build the professional network and access internships once she‚Äôs more certain. | Pros: Big cost savings (reduces need for large loans); time to clarify major; lower financial risk.  Cons: Delay in full four‚Äëyear campus networking and on‚Äëcampus internship pipelines; transfer requires planning to avoid credit loss and timeline slip. | 1) Select a target 4‚Äëyear (or 2‚Äì3) now and obtain articulation/transfer agreement details. 2) Work with CC advisor to choose fully transferable general ed + exploratory courses aligned to possible majors. 3) Aim for a strong GPA (target 3.5+ for competitive transfers) and document coursework. 4) Pursue internships, volunteer, faculty contacts, and CC leadership roles to start building experience and references. 5) Apply for scholarships and external internships; keep family finances and loan needs updated. 6) Visit target campuses in year 1 and meet transfer admissions reps. | If by the end of year 1 Alex is clear about her major and can secure significant scholarships or other funding to offset the 4‚Äëyear cost, consider transferring early. If GPA or credits fall behind transfer requirements, extend CC plan to recover (summer courses, tutoring). If a target major is highly competitive, re-evaluate required GPA/portfolio and consider applying to multiple transfer schools or staying an extra semester to strengthen application. |\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "// Create a system prompt instruction to override the default system prompt\n",
        "// Add the System Prompt (Persona) to behave like a decision intelligence assistant\n",
        "var systemPromptForDecisions = \"\"\"\n",
        "You are a Decision Intelligence Assistant. \n",
        "Assist the user in exploring options, reasoning through decisions, problem-solving.\n",
        "Apply systems thinking to the scenarios. \n",
        "Provide structured, logical, and comprehensive decision advice.\n",
        "\n",
        "Output Format Instructions:\n",
        "When generating Markdown, do not use any headings higher than ###. \n",
        "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
        "All top-level section headers should start at ### or lower. \n",
        "Never use ---, ***, or ___ for horizontal lines. There should be no horizontal lines in the output.\n",
        "For separation, use extra extra spacing. Do not any render horizontal lines.\n",
        "\"\"\";\n",
        "// Provide a description of the decision scenario and the desired output \n",
        "// Provide detailed Decision Scenario considerations and information about Alex (the decision-maker) \n",
        "var scenarioDecisionPrompt = \"\"\"\n",
        "Imagine you are advising a daughter named Alex who is deciding whether to enroll directly in a well-regarded four-year \n",
        "university or start at a community college to earn an associate degree first. \n",
        "\n",
        "Make a single recommendation based on the following decision factor details. \n",
        "Output the recommendation in a Markdown table format. \n",
        "\n",
        "Financial Considerations:\n",
        "Alex's four-year university will cost significantly more in tuition, housing, and related expenses \n",
        "(estimated $50,000-$60,000 per year). A two-year associate program at a local community college could \n",
        "save substantial money (estimated $3,000-$5,000 per year), but Alex may have to transfer to a \n",
        "four-year institution later to complete a bachelor's degree. The family can afford the four-year university, \n",
        "with some loans, but the cost is only a medium concern. \n",
        "\n",
        "Career and Major Uncertainty:\n",
        "Alex is not entirely sure what she wants to major in. She is torn between business, psychology, and \n",
        "possibly something in the arts. She worries that if she starts at the four-year university, \n",
        "she might switch majors and incur extra time and cost. On the other hand, \n",
        "community college might give her space to explore options, \n",
        "but transferring could mean adjusting to a new campus and curriculum midway through.\n",
        "\n",
        "Academic Consistency and Networking:\n",
        "Going straight to the four-year university would allow Alex to build early relationships with professors, \n",
        "join campus groups, and potentially secure internships or research opportunities. Starting at community college might \n",
        "delay those opportunities, but it could also let her explore different fields at a lower cost. \n",
        "She might miss out on the ‚Äúfull campus‚Äù experience early on, but transferring later means she could \n",
        "still build connections, just on a different timeline. \n",
        "\n",
        "Future Impact: \n",
        "Alex is unsure of the short-term future impact of her decision that might be hard to remediate. \n",
        "Alex wants a solid professional network and relevant experience when she graduates. \n",
        "Alex is not overly concerned about the social aspect of college, \n",
        "but feels she can build a quality network in a four-year university setting sooner. \n",
        "She is also concerned about taking on significant student loan debt. The decision affects not only her immediate academic path but \n",
        "also her long-term financial stability and career prospects. \n",
        "\"\"\";\n",
        "\n",
        "// How the prompt looks like to the LLM\n",
        "var scenarioDecisionPromptTemplate = $\"\"\"\n",
        "System Prompt: \n",
        "{systemPromptForDecisions}\n",
        "\n",
        "Request from the user: \n",
        "{scenarioDecisionPrompt}\n",
        "\"\"\";\n",
        "\n",
        "PromptExecutionSettings promptExecutionSettings = new();\n",
        "\n",
        "if (useAzureOpenAI)\n",
        "{\n",
        "    // Create a new Azure OpenAI Prompt Execution settings object\n",
        "    #pragma warning disable SKEXP0010\n",
        "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
        "        SetNewMaxCompletionTokensEnabled = true,\n",
        "        MaxTokens = 1500,\n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "else\n",
        "{\n",
        "    // Create a new OpenAI Prompt Execution settings object\n",
        "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "// Create a new KernelArguments object with the AzureOpenAI / OpenAI prompt execution settings\n",
        "KernelArguments kernelArguments = new KernelArguments(promptExecutionSettings);\n",
        "\n",
        "var promptResponseScenario = await semanticKernel.InvokePromptAsync(scenarioDecisionPromptTemplate, kernelArguments);\n",
        "var response = promptResponseScenario.GetValue<string>();\n",
        "\n",
        "// Display the response from the Semantic Kernel as Markdown\n",
        "response.DisplayAs(\"text/markdown\");"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".NET (C#)",
      "language": "C#",
      "name": ".net-csharp"
    },
    "language_info": {
      "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
      "kernelInfo": {
        "defaultKernelName": "csharp",
        "items": [
          {
            "aliases": [],
            "name": "csharp"
          }
        ]
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
