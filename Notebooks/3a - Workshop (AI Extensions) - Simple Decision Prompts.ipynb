{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"display: flex; align-items: center;\">\n",
        "  <img src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/SemanticKernelLogo.png\" width=\"40px\" style=\"margin-right: 10px;\">\n",
        "  <span style=\"font-size: 1.5em; font-weight: bold;\">3a - Workshop (AI Extensions) - Simple Decision Prompts</span>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decision Intelligence applied in this module:  \n",
        "* Listing of various decision-making frameworks and with their descriptions by using GenAI prompt engineering  \n",
        "* Creating custom AI personas with a system decision prompt  \n",
        "* Generating decision outputs using easier to consume formats (Markdown)     \n",
        "\n",
        "Prompts are the fundamental building blocks for eliciting effective responses from AI models. This module demonstrates how to use common prompt engineering techniques within Semantic Kernel. If you‚Äôve used ChatGPT or Microsoft Copilot, you‚Äôre already familiar with prompting: given an instruction, a language model predicts the most likely and relevant response. With Semantic Kernel, you can build applications, services, and APIs that execute these prompts.  \n",
        "\n",
        "For more information on using prompts with Semantic Kernel, visit: https://learn.microsoft.com/en-us/semantic-kernel/prompts/your-first-prompt  \n",
        "\n",
        "The process of carefully crafting questions or instructions for AI is called **Prompt Engineering**. Prompt Engineering involves designing and refining input prompts‚Äîtext or questions‚Äîso that the AI produces responses that are more relevant, useful, or accurate. The goal is to maximize the quality and clarity of the AI‚Äôs output, often by using specific wording, added context, or concrete examples within the prompt.\n",
        "\n",
        "By combining Decision Intelligence with Prompt Engineering, you can create ‚ÄúGenerative AI Decision Intelligence.‚Äù This approach leverages GenAI models to reason through complex tasks, gather intelligence, recommend decisions, and communicate results more effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 1 - Initialize Configuration Builder & Build the AI Orchestration "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the next two cells to:\n",
        "* Use the Configuration Builder to load the API secrets.  \n",
        "* Use the API configuration to build the AI orchestrator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 10.0.1</span></li><li><span>Microsoft.Extensions.Configuration.Json, 10.0.1</span></li><li><span>System.Text.Json, 10.0.1</span></li></ul></div></div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "// Import the required NuGet configuration packages\n",
        "#r \"nuget: Microsoft.Extensions.Configuration, 10.0.1\"\n",
        "#r \"nuget: Microsoft.Extensions.Configuration.Json, 10.0.1\"\n",
        "#r \"nuget: System.Text.Json, 10.0.1\"\n",
        "\n",
        "using Microsoft.Extensions.Configuration.Json;\n",
        "using Microsoft.Extensions.Configuration;\n",
        "using System.IO;\n",
        "using System;\n",
        "\n",
        "// Load the configuration settings from the local.settings.json and secrets.settings.json files\n",
        "// The secrets.settings.json file is used to store sensitive information such as API keys\n",
        "var configurationBuilder = new ConfigurationBuilder()\n",
        "    .SetBasePath(Directory.GetCurrentDirectory())\n",
        "    .AddJsonFile(\"local.settings.json\", optional: true, reloadOnChange: true)\n",
        "    .AddJsonFile(\"secrets.settings.json\", optional: true, reloadOnChange: true);\n",
        "var config = configurationBuilder.Build();\n",
        "\n",
        "// IMPORTANT: You ONLY NEED either Azure OpenAI or OpenAI connection info, not both.\n",
        "// Azure OpenAI Connection Info\n",
        "var azureOpenAIEndpoint = config[\"AzureOpenAI:Endpoint\"];\n",
        "var azureOpenAIAPIKey = config[\"AzureOpenAI:APIKey\"];\n",
        "var azureOpenAIModelDeploymentName = config[\"AzureOpenAI:ModelDeploymentName\"];\n",
        "// OpenAI Connection Info \n",
        "var openAIAPIKey = config[\"OpenAI:APIKey\"];\n",
        "var openAIModelId = config[\"OpenAI:ModelId\"];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 2.8.0-beta.1</span></li><li><span>Azure.Identity, 1.18.0-beta.2</span></li><li><span>Microsoft.Extensions.AI, 10.1.1</span></li><li><span>Microsoft.Extensions.AI.Abstractions, 10.1.1</span></li><li><span>Microsoft.Extensions.AI.OpenAI, 10.1.1-preview.1.25612.2</span></li><li><span>OpenAI, 2.8.0</span></li></ul></div></div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Azure OpenAI Service\n"
          ]
        }
      ],
      "source": [
        "// Import the Microdoft Extensions AI NuGet Packages\n",
        "#r \"nuget: Microsoft.Extensions.AI, 10.1.1\"\n",
        "#r \"nuget: Microsoft.Extensions.AI.Abstractions, 10.1.1\"\n",
        "#r \"nuget: Microsoft.Extensions.AI.OpenAI, 10.1.1-preview.1.25612.2\"\n",
        "// Import Azure & OpenAI NuGet Packages\n",
        "#r \"nuget: Azure.AI.OpenAI, 2.8.0-beta.1\"\n",
        "#r \"nuget: Azure.Identity, 1.18.0-beta.2\"\n",
        "#r \"nuget: OpenAI, 2.8.0\"\n",
        "\n",
        "using Azure;\n",
        "using Azure.AI.OpenAI;\n",
        "using Microsoft.Extensions.AI;\n",
        "using Microsoft.Extensions.Configuration;\n",
        "using OpenAI.Chat;\n",
        "using System.ClientModel;\n",
        "using System.ComponentModel;\n",
        "using System.Text.Json;\n",
        "\n",
        "// Set the flag to use Azure OpenAI or OpenAI. False to use OpenAI, True to use Azure OpenAI\n",
        "var useAzureOpenAI = true;\n",
        "IChatClient chatClient;\n",
        "\n",
        "// Create a new Semantic Kernel instance\n",
        "if (useAzureOpenAI)\n",
        "{\n",
        "    Console.WriteLine(\"Using Azure OpenAI Service\");\n",
        "\n",
        "    var apiKeyCredential = new ApiKeyCredential(azureOpenAIAPIKey);\n",
        "    var azureOpenAIClient = new AzureOpenAIClient(new Uri(azureOpenAIEndpoint), apiKeyCredential);\n",
        "\n",
        "    #pragma warning disable OPENAI001\n",
        "    chatClient = azureOpenAIClient.GetChatClient(azureOpenAIModelDeploymentName).AsIChatClient();\n",
        "}\n",
        "else\n",
        "{\n",
        "    Console.WriteLine(\"Using OpenAI Service\");\n",
        "\n",
        "    var apiKeyCredential = new ApiKeyCredential(azureOpenAIAPIKey);\n",
        "    var azureOpenAIClient = new AzureOpenAIClient(new Uri(azureOpenAIEndpoint), apiKeyCredential);\n",
        "\n",
        "    #pragma warning disable OPENAI001\n",
        "    chatClient = azureOpenAIClient.GetChatClient(azureOpenAIModelDeploymentName).AsIChatClient();\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 2 - Execute a Decision Prompt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Many LLMs and even SLMs have been trained on knowledge that includes decision frameworks & processes. This makes LLMs great assistants to:\n",
        "* Provide proper Decision Frames\n",
        "* Gather Intelligence (information) in order to make a decision\n",
        "* Recommend Decision Frameworks to make a high-quality decision\n",
        "* Provide feedback to evaluate a Decision\n",
        "\n",
        "Once the Semantic Kernel instance is built, it is ready to intake prompt instructions. In the prompt below, the Semantic Kernel is instructed to provide examples of decision frameworks \"trained into\" the knowledge of the configured AI model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are **five decision-making frameworks** that can help enhance the quality of decisions, along with brief descriptions of how each supports better analysis and reasoning:  \n",
            "\n",
            "---\n",
            "\n",
            "1. **SWOT Analysis (Strengths, Weaknesses, Opportunities, Threats)**  \n",
            "   - **Description:** SWOT is a strategic tool for evaluating internal and external factors affecting a decision or project.  \n",
            "   - **How it helps:** By systematically identifying strengths and weaknesses (internal factors) and opportunities and threats (external factors), it encourages a balanced view, prevents blind spots, and supports informed choice-making in business, personal, or policy contexts.  \n",
            "\n",
            "2. **Cost-Benefit Analysis (CBA)**  \n",
            "   - **Description:** CBA involves comparing the total expected costs of an option against its total expected benefits, expressed in monetary or measurable terms.  \n",
            "   - **How it helps:** It allows decision-makers to quantify trade-offs, prioritize high-return options, and justify choices with data. It is especially useful for financial, infrastructure, and policy decisions.  \n",
            "\n",
            "3. **OODA Loop (Observe‚ÄìOrient‚ÄìDecide‚ÄìAct)**  \n",
            "   - **Description:** Originating from military strategy, the OODA loop is a rapid iterative cycle for making decisions and adapting quickly to changing conditions.  \n",
            "   - **How it helps:** It promotes agility and continuous reassessment in dynamic environments, such as business competition, crisis management, or technology development.  \n",
            "\n",
            "4. **Decision Matrix (Weighted Scoring Model)**  \n",
            "   - **Description:** This method scores multiple alternatives against a set of weighted criteria to determine the most suitable choice.  \n",
            "   - **How it helps:** It brings structured objectivity to complex decisions with many factors to consider, reduces bias by making trade-offs explicit, and supports consensus-building in group decisions.  \n",
            "\n",
            "5. **Pros‚ÄìCons‚ÄìMitigation Analysis**  \n",
            "   - **Description:** This framework not only lists the positive and negative aspects of each option but also identifies strategies to reduce potential downsides.  \n",
            "   - **How it helps:** It expands traditional pros-and-cons analysis by adding a preventative thinking step, encouraging creative solutions and risk reduction strategies.  \n",
            "\n",
            "---\n",
            "\n",
            "If you‚Äôd like, I can also create a **comparative table** showing when each framework works best and the types of decisions they suit. Would you like me to prepare that?\n"
          ]
        }
      ],
      "source": [
        "using System.Text.Json;\n",
        "\n",
        "// A Decision Intelligence prompt to help with describing decision-making frameworks\n",
        "var simpleDecisionPrompt = \"\"\"\n",
        "Identify and list 5 decision-making frameworks that can enhance the quality of decisions. \n",
        "Briefly describe how each decision-making framework supports better analysis and reasoning in various scenarios. \n",
        "\"\"\";\n",
        "\n",
        "// Execute the prompt against the AI model\n",
        "var simplePromptResponse = await chatClient.GetResponseAsync(simpleDecisionPrompt);\n",
        "var responseString = simplePromptResponse.Messages[0].Contents[0].ToString();\n",
        "\n",
        "// Display the response from the AI model\n",
        "Console.WriteLine(responseString);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 3 - Execute a Decision Prompt with Streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Semantic Kernel supports prompt response streaming when invoking the prompt. This allows responses to be streamed to the client as soon as they are made available by the LLM and service. Below the same decision prompt is executed. However, notice that chunks are streamed and can be read by the user as soon as they appear. \n",
        "\n",
        "> üìù **Note:** An average human can read between 25-40 Tokens / second. Therefore, while streaming certainly helps with providing AI output to the user, it begins to lose its effectiveness at large token velocity. Furthermore, certain intermediate and governance (Responsible AI) outputs can become more complex to integrat with streaming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are **five decision-making frameworks** and how they help improve analysis, reasoning, and outcomes:\n",
            "\n",
            "1. **OODA Loop (Observe‚ÄìOrient‚ÄìDecide‚ÄìAct)**  \n",
            "   - **Description:** Developed by military strategist John Boyd, the OODA loop emphasizes iterative decision-making in fast-changing situations.  \n",
            "   - **How it helps:** It encourages rapid situational awareness (Observe), contextual framing (Orient), selection of the best action (Decide), and immediate implementation (Act), while continuously adapting to new information. This helps in dynamic environments such as business competition, crisis management, or negotiations.\n",
            "\n",
            "2. **SWOT Analysis (Strengths, Weaknesses, Opportunities, Threats)**  \n",
            "   - **Description:** A strategic planning tool that examines internal strengths and weaknesses alongside external opportunities and threats.  \n",
            "   - **How it helps:** It forces decision-makers to assess both internal capabilities and external factors, ensuring a balanced view. This prevents overly optimistic or pessimistic choices and supports strategic alignment.\n",
            "\n",
            "3. **Cost-Benefit Analysis (CBA)**  \n",
            "   - **Description:** A quantitative and qualitative method of weighing the projected costs of a decision against its expected benefits.  \n",
            "   - **How it helps:** It helps to assign value to different outcomes, prioritize resource allocation, and compare alternatives objectively. This framework is useful in project evaluation, policy-making, and investment decisions.\n",
            "\n",
            "4. **Six Thinking Hats**  \n",
            "   - **Description:** Created by Edward de Bono, this method assigns different ‚Äúhats‚Äù to separate thinking modes‚Äîfacts (White), feelings (Red), cautions (Black), benefits (Yellow), creativity (Green), and process control (Blue).  \n",
            "   - **How it helps:** It encourages viewing a problem from multiple perspectives systematically, avoiding groupthink, and fostering balanced reasoning. Useful in team decision-making and problem-solving.\n",
            "\n",
            "5. **PDCA Cycle (Plan‚ÄìDo‚ÄìCheck‚ÄìAct)**  \n",
            "   - **Description:** A continuous improvement model originating from quality management, designed for iterative testing of ideas.  \n",
            "   - **How it helps:** It encourages planning carefully, implementing gradually, monitoring results, and making iterative adjustments. Especially valuable for process optimization, operational decisions, and innovation testing.\n",
            "\n",
            "---\n",
            "\n",
            "If you‚Äôd like, I can also **create a decision matrix** that compares these five frameworks by speed, complexity, data requirements, and suitability for different environments. Would you like me to prepare that next?"
          ]
        }
      ],
      "source": [
        "// Same Decision Intelligence prompt executed using Streaming output chunks \n",
        "await foreach (var streamChunk in chatClient.GetStreamingResponseAsync(simpleDecisionPrompt))\n",
        "{\n",
        "   Console.Write(streamChunk);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 4 - Execute a Decision Prompt with Improved Output Formatting  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generative AI models have an inherent ability to not only provide decision reasoning analysis, but also format the output in a desired format. This could be as simple as instructing the Generative AI model to format the decision as a single sentence, paragraphs or lists. However more sophisticated output generations can be instructed. For example, the GenAI model can output Markdown or even extract information and fill in a desired schema (JSON). Specifically for Decision Intelligence, you can ask the GenAI models to apply decision communication frameworks to the generation as well. \n",
        "\n",
        "Execute the simple decision prompt below with Markdown formatting output. This table can now be rendered in a Markdown document for easy human comprehension. Markdown tables and other formats can be used on web sites, document, programming code etc. Even Generative AI models understand Markdown format, which can not only be used for output but inside input prompts.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "| Decision-Making Framework | Description | How It Enhances Analysis & Reasoning |\n",
              "|---------------------------|-------------|---------------------------------------|\n",
              "| SWOT Analysis | Evaluates Strengths, Weaknesses, Opportunities, and Threats related to a situation. | Encourages a balanced assessment of internal and external factors, allowing for better strategic alignment and opportunity-risk analysis. |\n",
              "| Cost-Benefit Analysis (CBA) | Compares the costs and expected benefits of different options. | Provides a quantitative basis for choice, helping to identify the option with the highest net value. |\n",
              "| Decision Matrix Analysis | Ranks options against weighted criteria. | Offers a structured and transparent method for comparing alternatives, reducing bias and improving objectivity. |\n",
              "| OODA Loop (Observe, Orient, Decide, Act) | A cyclical decision model for continuous assessment and adaptation. | Supports rapid, iterative decision-making in dynamic environments, fostering flexibility and responsiveness. |\n",
              "| Six Thinking Hats | Encourages examining a problem from multiple perspectives (emotional, factual, creative, critical, etc.). | Improves comprehensive reasoning by ensuring diverse viewpoints are considered before making a decision. |"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "// A new decision prompt to help with describing decision-making frameworks using table Markdown format\n",
        "var simpleDecisionPromptWithMarkdownFormat = \"\"\"\n",
        "Identify and list 5 decision-making frameworks that can enhance the quality of decisions. \n",
        "Briefly describe how each decision-making framework supports better analysis and reasoning in various scenarios.\n",
        "\n",
        "Format the response using only a Markdown table. Only return a Markdown table. \n",
        "Do not enclose the table in triple backticks.\n",
        "\"\"\";\n",
        "\n",
        "// Execute the prompt against the AI model\n",
        "var simplePromptResponseWithMarkdownFormat = await chatClient.GetResponseAsync(simpleDecisionPromptWithMarkdownFormat);\n",
        "var responseStringWithMarkdownFormat = simplePromptResponseWithMarkdownFormat.Messages[0].Contents[0].ToString();\n",
        "\n",
        "// Display the response from the Semantic Kernel as Markdown\n",
        "responseStringWithMarkdownFormat.DisplayAs(\"text/markdown\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 5 - Execute a Decision Prompt with a Custom Prompt Execution Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Semantic Kernel supports the configuration of prompt execution. The typical OpenAI and Azure OpenAI settings are exposed as configuration options that provide a different prompt experience. Try changing the MaxTokens, Temperature or other settings.\n",
        "\n",
        "> **üìù Note:** The supported prompt settings are dependent on the API plus the specific model version. For example, an AI model paired with an older API may not expose all the configuration settings available. Conversely, a new preview model may not have all the settings available until it becomes generally available. Types of model execution (general versus reasoning) will also have different execution setting parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "| Framework | How it supports better analysis and reasoning |\n",
              "|---|---|\n",
              "| OODA Loop (Observe‚ÄìOrient‚ÄìDecide‚ÄìAct) | Structures fast, iterative cycles of sensing and response; improves situational awareness, enables rapid hypothesis testing and course corrections as conditions change. |\n",
              "| Decision Matrix / Weighted Scoring | Breaks choices into criteria with explicit weights and scores; forces trade-off analysis, reduces bias by making priorities and evaluations transparent and comparable. |\n",
              "| Cost‚ÄìBenefit Analysis (CBA) | Converts options into comparable monetary (or utility) terms to quantify trade-offs and opportunity costs; clarifies net value and supports rational resource allocation. |\n",
              "| Bayesian Reasoning | Treats beliefs as probabilities and updates them with new evidence; makes uncertainty explicit, improves calibration of expectations, and guides decisions under incomplete information. |\n",
              "| Pre‚Äëmortem Analysis | Imagines future failure to identify hidden assumptions, risks, and failure modes before acting; encourages mitigation planning and reduces overconfidence and blind spots. |"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PromptExecutionSettings promptExecutionSettings = new();\n",
        "\n",
        "if (useAzureOpenAI)\n",
        "{\n",
        "    // Create a new Azure OpenAI Prompt Execution settings object\n",
        "    #pragma warning disable SKEXP0010\n",
        "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
        "        SetNewMaxCompletionTokensEnabled = true,\n",
        "        MaxTokens = 1500,\n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "else\n",
        "{\n",
        "    // Create a new OpenAI Prompt Execution settings object\n",
        "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "\n",
        "// Create a new KernelArguments object with the OpenAI prompt execution settings\n",
        "KernelArguments kernelArguments = new KernelArguments(promptExecutionSettings);\n",
        "\n",
        "var promptResponseWithOpenAI = await semanticKernel.InvokePromptAsync(simpleDecisionPromptWithMarkdownFormat, kernelArguments);\n",
        "var response = promptResponseWithOpenAI.GetValue<string>();\n",
        "\n",
        "// Display the response from the Semantic Kernel as Markdown\n",
        "response.DisplayAs(\"text/markdown\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 6 - Execute a Decision Prompt with a System Prompt (Custom AI Persona)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When building Decision Intelligence prompts, all the typical best practices of prompt engineering apply when using Semantic Kernel.  Such as: \n",
        "* Make the prompt more specific (i.e. decision intelligence)\n",
        "* Add structure to the output with formatting\n",
        "* Provide examples with few-shot prompting\n",
        "* Instruct the AI what to do to avoid doing something else\n",
        "* Provide context (additional information) to the AI\n",
        "* Using Roles in Chat Completion API prompts\n",
        "* Give your AI words of encouragement  \n",
        "\n",
        "A key best practice is to provide a common behavior across all the LLM interactions in a system prompt. This system prompt is passed in on every single call the LLM with Semantic Kernel. By passing the same (or similar) system prompt with every prompt gives your Generative AI system a common persona. This common persona is the foundational building block of building AI agents; where the desired behavior is to have each agent have a unique persona/behavior every time you interact with that agent.\n",
        "\n",
        "Execute the cell below with a dynamic prompt template. Notice the different behavior of the output for decision frameworks. Based on the new system prompt instructions, the decision framework responses are much more robust with decision intelligence information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": []
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "// Create a System Prompt instruction to override the default system prompt\n",
        "// Add the System Prompt (Persona) to behave like a Decision Intelligence assistant\n",
        "var systemPromptForDecisions = \"\"\"\n",
        "You are a Decision Intelligence Assistant. \n",
        "Assist the user in exploring options, reasoning through decisions, problem-solving.\n",
        "Apply systems thinking to the scenarios. \n",
        "Provide structured, logical, and comprehensive decision advice.\n",
        "\n",
        "Output Format Instructions: \n",
        "When generating Markdown, do not use any headings higher than ###. \n",
        "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
        "All top-level section headers should start at ### or lower. \n",
        "Never use ---, ***, or ___ for horizontal lines. There should be no horizontal lines in the output.\n",
        "For separation, use extra extra spacing. Do not any render horizontal lines.\n",
        "\n",
        "Format the response using only a Markdown table. Only return a Markdown table. \n",
        "Do not enclose the table in triple backticks.\n",
        "\"\"\";\n",
        "var simpleDecisionPrompt = \"\"\"\n",
        "Recommend the top 5 decision frameworks that can be used for daily situations to make various decisions.\n",
        "These frameworks should be very easy to understand and apply to various scenarios.\n",
        "\"\"\";\n",
        "\n",
        "// How the prompt looks like to the LLM\n",
        "var simpleDecisionPromptTemplate = $\"\"\"\n",
        "System Prompt: \n",
        "{systemPromptForDecisions}\n",
        "\n",
        "Request from the user: \n",
        "{simpleDecisionPrompt}\n",
        "\"\"\";\n",
        "\n",
        "PromptExecutionSettings promptExecutionSettings = new();\n",
        "\n",
        "if (useAzureOpenAI)\n",
        "{\n",
        "    // Create a new Azure OpenAI Prompt Execution settings object\n",
        "    #pragma warning disable SKEXP0010\n",
        "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
        "        SetNewMaxCompletionTokensEnabled = true,\n",
        "        MaxTokens = 1500,\n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "else\n",
        "{\n",
        "    // Create a new OpenAI Prompt Execution settings object\n",
        "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "// Create a new KernelArguments object with the AzureOpenAI / OpenAI prompt execution settings\n",
        "KernelArguments kernelArguments = new KernelArguments(promptExecutionSettings);\n",
        "\n",
        "\n",
        "var promptResponseWithTemplate = await semanticKernel.InvokePromptAsync(simpleDecisionPrompt, kernelArguments);\n",
        "var response = promptResponseWithTemplate.GetValue<string>();\n",
        "\n",
        "// Display the response from the Semantic Kernel as Markdown\n",
        "response.DisplayAs(\"text/markdown\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----\n",
        "### Step 7 - Execute a Decision Scenario with a System Prompt (Custom AI Persona)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this step a decision scenario will be introduced requiring analysis and a recommendation performed by Artificial Intelligence. The full **Decision Intelligence** framework will not be used, rather a simple request for Artificial Intelligence to recommend a path forward (recommendation) for the human user to ultimately make the final decision.  \n",
        "\n",
        "**Decision Scenario:** Your high school daughter Alex is deciding whether to enroll directly in a four-year university or start at a community college to earn an associate degree first. These are Alex's main decision factors: financial, career uncertainty, academic consistency and future impact. In addition, you have all the decision factor detailed data available to pass to the GenAI model prompt. You are looking for an impartial (non-family) recommendation. Can Artificial Intelligence be that impartial judge to help Alex decide? \n",
        "\n",
        "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-SimpleDecision-College.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "dotnet_interactive": {
          "language": "csharp"
        },
        "polyglot_notebook": {
          "kernelName": "csharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### Recommendation\n",
              "\n",
              "| Recommendation | Why (concise rationale) | Key trade-offs (most important) | Concrete next steps (first 12 months) | Contingencies / when to change course |\n",
              "|---|---:|---|---|---|\n",
              "| Start at the community college with an intentional, transfer-focused plan to a well-regarded four‚Äëyear university after 1‚Äì2 years. | Saves substantial money while giving Alex low‚Äërisk space to explore majors (business, psychology, arts) and avoid costly major-switching at the expensive four‚Äëyear; preserve ability to transfer later to build the professional network and access internships once she‚Äôs more certain. | Pros: Big cost savings (reduces need for large loans); time to clarify major; lower financial risk.  Cons: Delay in full four‚Äëyear campus networking and on‚Äëcampus internship pipelines; transfer requires planning to avoid credit loss and timeline slip. | 1) Select a target 4‚Äëyear (or 2‚Äì3) now and obtain articulation/transfer agreement details. 2) Work with CC advisor to choose fully transferable general ed + exploratory courses aligned to possible majors. 3) Aim for a strong GPA (target 3.5+ for competitive transfers) and document coursework. 4) Pursue internships, volunteer, faculty contacts, and CC leadership roles to start building experience and references. 5) Apply for scholarships and external internships; keep family finances and loan needs updated. 6) Visit target campuses in year 1 and meet transfer admissions reps. | If by the end of year 1 Alex is clear about her major and can secure significant scholarships or other funding to offset the 4‚Äëyear cost, consider transferring early. If GPA or credits fall behind transfer requirements, extend CC plan to recover (summer courses, tutoring). If a target major is highly competitive, re-evaluate required GPA/portfolio and consider applying to multiple transfer schools or staying an extra semester to strengthen application. |\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "// Create a system prompt instruction to override the default system prompt\n",
        "// Add the System Prompt (Persona) to behave like a decision intelligence assistant\n",
        "var systemPromptForDecisions = \"\"\"\n",
        "You are a Decision Intelligence Assistant. \n",
        "Assist the user in exploring options, reasoning through decisions, problem-solving.\n",
        "Apply systems thinking to the scenarios. \n",
        "Provide structured, logical, and comprehensive decision advice.\n",
        "\n",
        "Output Format Instructions:\n",
        "When generating Markdown, do not use any headings higher than ###. \n",
        "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
        "All top-level section headers should start at ### or lower. \n",
        "Never use ---, ***, or ___ for horizontal lines. There should be no horizontal lines in the output.\n",
        "For separation, use extra extra spacing. Do not any render horizontal lines.\n",
        "\"\"\";\n",
        "// Provide a description of the decision scenario and the desired output \n",
        "// Provide detailed Decision Scenario considerations and information about Alex (the decision-maker) \n",
        "var scenarioDecisionPrompt = \"\"\"\n",
        "Imagine you are advising a daughter named Alex who is deciding whether to enroll directly in a well-regarded four-year \n",
        "university or start at a community college to earn an associate degree first. \n",
        "\n",
        "Make a single recommendation based on the following decision factor details. \n",
        "Output the recommendation in a Markdown table format. \n",
        "\n",
        "Financial Considerations:\n",
        "Alex's four-year university will cost significantly more in tuition, housing, and related expenses \n",
        "(estimated $50,000-$60,000 per year). A two-year associate program at a local community college could \n",
        "save substantial money (estimated $3,000-$5,000 per year), but Alex may have to transfer to a \n",
        "four-year institution later to complete a bachelor's degree. The family can afford the four-year university, \n",
        "with some loans, but the cost is only a medium concern. \n",
        "\n",
        "Career and Major Uncertainty:\n",
        "Alex is not entirely sure what she wants to major in. She is torn between business, psychology, and \n",
        "possibly something in the arts. She worries that if she starts at the four-year university, \n",
        "she might switch majors and incur extra time and cost. On the other hand, \n",
        "community college might give her space to explore options, \n",
        "but transferring could mean adjusting to a new campus and curriculum midway through.\n",
        "\n",
        "Academic Consistency and Networking:\n",
        "Going straight to the four-year university would allow Alex to build early relationships with professors, \n",
        "join campus groups, and potentially secure internships or research opportunities. Starting at community college might \n",
        "delay those opportunities, but it could also let her explore different fields at a lower cost. \n",
        "She might miss out on the ‚Äúfull campus‚Äù experience early on, but transferring later means she could \n",
        "still build connections, just on a different timeline. \n",
        "\n",
        "Future Impact: \n",
        "Alex is unsure of the short-term future impact of her decision that might be hard to remediate. \n",
        "Alex wants a solid professional network and relevant experience when she graduates. \n",
        "Alex is not overly concerned about the social aspect of college, \n",
        "but feels she can build a quality network in a four-year university setting sooner. \n",
        "She is also concerned about taking on significant student loan debt. The decision affects not only her immediate academic path but \n",
        "also her long-term financial stability and career prospects. \n",
        "\"\"\";\n",
        "\n",
        "// How the prompt looks like to the LLM\n",
        "var scenarioDecisionPromptTemplate = $\"\"\"\n",
        "System Prompt: \n",
        "{systemPromptForDecisions}\n",
        "\n",
        "Request from the user: \n",
        "{scenarioDecisionPrompt}\n",
        "\"\"\";\n",
        "\n",
        "PromptExecutionSettings promptExecutionSettings = new();\n",
        "\n",
        "if (useAzureOpenAI)\n",
        "{\n",
        "    // Create a new Azure OpenAI Prompt Execution settings object\n",
        "    #pragma warning disable SKEXP0010\n",
        "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
        "        SetNewMaxCompletionTokensEnabled = true,\n",
        "        MaxTokens = 1500,\n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "else\n",
        "{\n",
        "    // Create a new OpenAI Prompt Execution settings object\n",
        "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
        "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
        "        // Temperature = 0.3,\n",
        "        TopP = 1.0, \n",
        "        FrequencyPenalty = 0.0, \n",
        "        PresencePenalty = 0.0\n",
        "        };\n",
        "}\n",
        "// Create a new KernelArguments object with the AzureOpenAI / OpenAI prompt execution settings\n",
        "KernelArguments kernelArguments = new KernelArguments(promptExecutionSettings);\n",
        "\n",
        "var promptResponseScenario = await semanticKernel.InvokePromptAsync(scenarioDecisionPromptTemplate, kernelArguments);\n",
        "var response = promptResponseScenario.GetValue<string>();\n",
        "\n",
        "// Display the response from the Semantic Kernel as Markdown\n",
        "response.DisplayAs(\"text/markdown\");"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".NET (C#)",
      "language": "C#",
      "name": ".net-csharp"
    },
    "language_info": {
      "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
      "kernelInfo": {
        "defaultKernelName": "csharp",
        "items": [
          {
            "aliases": [],
            "name": "csharp"
          }
        ]
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
