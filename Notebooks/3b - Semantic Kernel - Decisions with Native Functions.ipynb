{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;padding-right: 10px\" width =\"40px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/SemanticKernelLogo.png\">\n",
    "\n",
    "## Semantic Kernel - Decisions with Native Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Intelligence applied in this module:  \n",
    "* Selecting of a Decision-mMking framework dynamically using native code  \n",
    "* Decision Scenario: Using a Monte Carlo Simulation to provide an estimate of decsision uncertainty  \n",
    "* Provide a range for Decision Uncertainty using Confidence Intervals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Kernel Functions are the core building blocks of functionality for intelligent AI orchestration. Semantic Kernel functions usually have a single responsibility to perform. For example, a Sementic Kernel function can: send an e-mail, call an API, recommend a reasoning framework for a high-stakes decision etc. \n",
    "\n",
    "What makes Semantic Kernel functions so special? Can't one just produce similar outcomes by using a prompt in an LLM or just writing a software program? In order to answer that, one has to look at what makes GenAI so innovative. The GenAI models have a unique ability to process instructions with reasoning and logic. This allows these models to behave almost like a human decision maker. Even with basic prompts, GenAI models perform reasonably well. However, providing GenAI models with additional functions allows them to gain access to business processes, data and basically anything a GenAI model should consider when performing AI orchestration. \n",
    "\n",
    "For example, imagine you want to prepare a great Thanksgiving dinner and want to get help from a GenAI cooking application to create a new recipe. You enter what you want todo and it comes up with the most delicious looking feast for Thanksgiving. However, there is a problem it used ingredients and recommended using cooking appliances that you do not own! You could enter all of the ingredients and keep prompting until it narrowed down the what you could realistically make. Wouldn't it be better if the GenAI cooking application had access to: your available ingredients, your time availability, kitchen appliances and even your allergic preferences. Now the GenAI model can craft a Thanksgiving feast understanding the parameters and data without having to be guided. This is exactly what Semantic Kernel functions provide.\n",
    "\n",
    "Semantic Kernel functions come in two flavors: semantic functions and native functions. Native Functions provide the ability for Semantic Kernel to orchestrate plans, agents and reasoning paths using native functions (methods) of the language runtimes of C#, Python or Java. This allows AI architects to re-purpose existing business processes, APIs and other complex tasks that require a programming language. The image below illustrates the core value of native functions.  \n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"400px\" src=\"https://learn.microsoft.com/en-us/semantic-kernel/media/native-function-explainer.png\">\n",
    "\n",
    "For example, you may want to expose a native function that has access to a database or calls an API into business data. This is not possible currently with semantic functions and AI prompts.  \n",
    "\n",
    "Learn more about Semantic Kernel Native Functions: https://learn.microsoft.com/en-us/semantic-kernel/agents/plugins/using-the-kernelfunction-decorator?tabs=Csharp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Initialize Configuration Builder & Build the Semantic Kernel Orchestration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next two cells to:\n",
    "* Use the Configuration Builder to load the API secrets.  \n",
    "* Use the API configuration to build the Semantic Kernel orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration.Json, 9.0.4</span></li><li><span>Microsoft.SemanticKernel, 1.47.0</span></li><li><span>Microsoft.SemanticKernel.Plugins.Core, 1.47.0-alpha</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 9.0.4\"\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.47\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Plugins.Core, 1.47-alpha\"\n",
    "\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "using System.IO;\n",
    "\n",
    "var configurationBuilder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"local.settings.json\", optional: true, reloadOnChange: true)\n",
    "    .AddJsonFile(\"secrets.settings.json\", optional: true, reloadOnChange: true);\n",
    "var config = configurationBuilder.Build();\n",
    "\n",
    "// IMPORTANT: You ONLY NEED either Azure OpenAI or OpenAI connectiopn info, not both.\n",
    "// Azure OpenAI Connection Info\n",
    "var azureOpenAIEndpoint = config[\"AzureOpenAI:Endpoint\"];\n",
    "var azureOpenAIAPIKey = config[\"AzureOpenAI:APIKey\"];\n",
    "var azureOpenAIModelDeploymentName = config[\"AzureOpenAI:ModelDeploymentName\"];\n",
    "// OpenAI Connection Info \n",
    "var openAIAPIKey = config[\"OpenAI:APIKey\"];\n",
    "var openAIModelId = config[\"OpenAI:ModelId\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI Service\n"
     ]
    }
   ],
   "source": [
    "Kernel semanticKernel;\n",
    "\n",
    "// Set the flag to use Azure OpenAI or OpenAI. False to use OpenAI, True to use Azure OpenAI\n",
    "var useAzureOpenAI = true;\n",
    "\n",
    "// Create a new Semantic Kernel instance\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    Console.WriteLine(\"Using Azure OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddAzureOpenAIChatCompletion(\n",
    "            deploymentName: azureOpenAIModelDeploymentName,\n",
    "            endpoint: azureOpenAIEndpoint,\n",
    "            apiKey: azureOpenAIAPIKey)\n",
    "        .Build();\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"Using OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddOpenAIChatCompletion(\n",
    "            modelId: openAIModelId,\n",
    "            apiKey: openAIAPIKey)\n",
    "        .Build();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create a Simple Native Function in Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to create a very simple native function that uses a C# inline method. Notice the native function takes no parameters. It retrieves the name of a productivity decision framework to use. In this case that return name is hard-coded to \"Price's Law\".\n",
    "\n",
    "Execute the cell below to invoke the function. Note the function return instantly, as it is not calling any GenAI service. This function is simply being invoked by the Semantic Kernel wrapper.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price's Law\n"
     ]
    }
   ],
   "source": [
    "// Create a function from an inline (lambda) method\n",
    "var nameOfProductivityFramework = semanticKernel.CreateFunctionFromMethod(() => \"Price's Law\", \"GetNameOfProductivityFramework\", \"Retrieves the name of the Productivity Framework to use.\");\n",
    "\n",
    "// Invoke the function using Semantic Kernel\n",
    "var response = await semanticKernel.InvokeAsync(nameOfProductivityFramework);\n",
    "Console.WriteLine(response);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create a Native Function in Semantic Kernel with Dynamic Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to create a native function that takes a parameter as input. This shows that C# native functions can have different execution paths. The execution paths can obviously be quite complex. Basically, any C# logic flow will work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price's Law\n",
      "Pareto Principle\n"
     ]
    }
   ],
   "source": [
    "// Create a function from an inline (lambda) method with parameters\n",
    "var nameOfProductivityFramework = semanticKernel.CreateFunctionFromMethod((string typeOfProductivity) => (typeOfProductivity == \"Sales\") ? \"Price's Law\" : \"Pareto Principle\", \"GetNameOfProductivityFramework\", \"Retrieves the name of the Productivity Framework to use.\");\n",
    "\n",
    "// Pass the \"Sales\" parameter to the function\n",
    "var kernelArguments = new KernelArguments()\n",
    "{\n",
    "    [\"typeOfProductivity\"] = \"Sales\"\n",
    "};\n",
    "var response = await semanticKernel.InvokeAsync(nameOfProductivityFramework, kernelArguments);\n",
    "Console.WriteLine(response);\n",
    "\n",
    "// Pass the \"Other\" parameter to the function\n",
    "var kernelArgumentsOther = new KernelArguments()\n",
    "{\n",
    "    [\"typeOfProductivity\"] = \"Other\"\n",
    "};\n",
    "var responseOther = await semanticKernel.InvokeAsync(nameOfProductivityFramework, kernelArgumentsOther);\n",
    "Console.WriteLine(responseOther);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Use Native Functions To Simulate the Uncertainty of a Decision  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📜 \"The best way to predict the future is to simulate it. And the best way to simulate it is with Monte Carlo.\"\n",
    ">\n",
    "> -- <cite>Nassim Nicholas Taleb (Lebanese-American essayist, scholar, best known for his work on probability)</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complex decisions, native functions can use statitics, advanced probabilistic algorithms, analytics, machine learning, AI etc. that have been relied on in software for decades. One such method is Monte Carlo Simulations. These powerful Monte Carlo simulation techniques are used everywhere: risk management, sports gambling, medical decision-making, game theory, energy market forecasting etc.  In simple terms, a Monte Carlo simulation is basically a series of many runs testing different plausable parameters. Running a Monte Carlo simulation many times results in an output of a plausible range.  \n",
    "\n",
    "An simple use-case for a Monte Carlo simulation is to provide a realistic range for an average probability. Imagine you want to illustrate the uncertainty of a decision that you have calculated to be 70% successful. On \"average\" the probability of success can be interpreted as 70%. However, what is the range of possible succcessesi if that 70% decision model is run 100x? A Monte Carlo simulation can help solve that answer.\n",
    "\n",
    "Run the cell below to create a new KernelFunction that will take in the confidence parameter and output a simple string with the lower and upper bounds of a 95% confidence interval. A 95% Confidence Interval output will tell us if we execute this calculate decision 100x (times) that has a 70% success probability, what is the realistic range of success in those 100x (times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Add the System.ComponentModel namespace to use the Description attribute\n",
    "using System.ComponentModel;\n",
    "\n",
    "[KernelFunction]\n",
    "public string RetrieveConfidenceIntervalMonteCarlo(\n",
    "    [Description(\"Claimed Probability Percentage\")] int probability)\n",
    "{\n",
    "    const int NUMBEROFSIMULATIONS = 100000; // 100,000 simulations, make this smaller for faster results\n",
    "    Console.WriteLine($\"Simulating {NUMBEROFSIMULATIONS:n0} iterations with a claimed decision confidence of {probability}%...\");\n",
    "\n",
    "    var random = new Random();  // Add seed for reproducibility\n",
    "    var bootstrapConfidenceScores = new List<double>();\n",
    "    for (int i = 0; i != NUMBEROFSIMULATIONS; i++) // Bootstrap Simulations (bootstrap estimates)\n",
    "    {\n",
    "        var bootstrapSample = new List<double>();\n",
    "        for (int j = 0; j != 100; j++)\n",
    "        {\n",
    "            var randomIndex = random.Next(0, 100);\n",
    "\n",
    "            if (randomIndex < probability)\n",
    "            {\n",
    "                bootstrapSample.Add(1);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        bootstrapConfidenceScores.Add(bootstrapSample.Count());\n",
    "    }\n",
    "\n",
    "    // Sort the confidence scores to calculate the percentiles\n",
    "    var bootstrapConfidenceScoresSorted = bootstrapConfidenceScores.OrderBy(a => a).ToList();\n",
    "    // Calculate the 2.5% and 97.5% percentiles\n",
    "    var lowerPercentileIndex = Convert.ToInt32(0.025 * NUMBEROFSIMULATIONS);\n",
    "    var topPercentileIndex = Convert.ToInt32(0.975 * NUMBEROFSIMULATIONS);\n",
    "\n",
    "    var lowerPercentile = Math.Round(bootstrapConfidenceScoresSorted[lowerPercentileIndex], 3);\n",
    "    var upperPercentile = Math.Round(bootstrapConfidenceScoresSorted[topPercentileIndex], 3);\n",
    "\n",
    "    var confidenceUncertaintyRange = $\"95% Confidence Interval of a {probability}% success model: {lowerPercentile} to {upperPercentile} successful decision outcomes of 100 decisions made.\";\n",
    "    return confidenceUncertaintyRange;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to invoke the native Kernel function. This will run a Monte Carlo Simulation with 100,000 simulations of a decision with a confidence (probability) of 70% being run 100x. Basically, this will provide the uncertainty range if you had made 100 decisions of the same 70% success decision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating 100,000 iterations with a claimed decision confidence of 70%...\n",
      "95% Confidence Interval of a 70% success model: 61 to 79 successful decision outcomes of 100 decisions made.\n"
     ]
    }
   ],
   "source": [
    "var retrieveConfidenceInterval = semanticKernel.CreateFunctionFromMethod(\n",
    "    RetrieveConfidenceIntervalMonteCarlo, \"RetrieveConfidenceIntervalMonteCarlo\", \n",
    "    \"Generates Confidence Interval from provided Confidence Percentage\");\n",
    "\n",
    "// Change the probability to another integer and invoke the function, to see other Confidence Intervals \n",
    "var kernelArgumentsConfidence70 = new KernelArguments()\n",
    "{\n",
    "    [\"probability\"] = 70\n",
    "};\n",
    "var confidenceIntervalRange70 = semanticKernel.InvokeAsync(retrieveConfidenceInterval, kernelArgumentsConfidence70); \n",
    "Console.WriteLine(confidenceIntervalRange70.Result);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
