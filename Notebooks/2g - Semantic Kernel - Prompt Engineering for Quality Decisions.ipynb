{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;padding-right: 10px\" width =\"40px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/SemanticKernelLogo.png\">\n",
    "\n",
    "## Semantic Kernel - Prompt Engineering for Quality Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Intelligence applied in this module:  \n",
    "* Optimizing prompts for logic, reasoning and decisions\n",
    "* Examples of applying decision intelligence techniques in prompts and their output effect \n",
    "* Prompt techniques such as Chain of Thought to improve the quality of the decision reasoning and outcome \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, the Semantic Kernel ability to chat completion experience will be used to optimize system prompts (personas) and instructive prompts. No new specific Semantic Kernel functionality will be introduced. This module will focus on introducing decision intelligence prompting techniques.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Initialize Configuration Builder & Build the Semantic Kernel Orchestration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next two cells to:\n",
    "* Use the Configuration Builder to load the API secrets.  \n",
    "* Use the API configuration to build the Semantic Kernel orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 9.0.0</span></li><li><span>Microsoft.Extensions.Configuration.Json, 9.0.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import the required NuGet configuration packages\n",
    "#r \"nuget: Microsoft.Extensions.Configuration, 9.0.0\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 9.0.0\"\n",
    "\n",
    "using Microsoft.Extensions.Configuration.Json;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using System.IO;\n",
    "\n",
    "// Load the configuration settings from the local.settings.json and secrets.settings.json files\n",
    "// The secrets.settings.json file is used to store sensitive information such as API keys\n",
    "var configurationBuilder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"local.settings.json\", optional: true, reloadOnChange: true)\n",
    "    .AddJsonFile(\"secrets.settings.json\", optional: true, reloadOnChange: true);\n",
    "var config = configurationBuilder.Build();\n",
    "\n",
    "// IMPORTANT: You ONLY NEED either Azure OpenAI or OpenAI connectiopn info, not both.\n",
    "// Azure OpenAI Connection Info\n",
    "var azureOpenAIEndpoint = config[\"AzureOpenAI:Endpoint\"];\n",
    "var azureOpenAIAPIKey = config[\"AzureOpenAI:APIKey\"];\n",
    "var azureOpenAIModelDeploymentName = config[\"AzureOpenAI:ModelDeploymentName\"];\n",
    "// OpenAI Connection Info \n",
    "var openAIAPIKey = config[\"OpenAI:APIKey\"];\n",
    "var openAIModelId = config[\"OpenAI:ModelId\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.DependencyInjection, 9.0.0</span></li><li><span>Microsoft.SemanticKernel, 1.36.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI Service\r\n"
     ]
    }
   ],
   "source": [
    "// Install the required NuGet packages\n",
    "// Note: This also installs the Dependency Injection Package to retrieve the ChatCompletionService\n",
    "#r \"nuget: Microsoft.Extensions.DependencyInjection, 9.0.0\"\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.36.1\"\n",
    "\n",
    "using Microsoft.Extensions.DependencyInjection.Extensions;\n",
    "using Microsoft.Extensions.DependencyInjection;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "Kernel semanticKernel;\n",
    "\n",
    "// Set the flag to use Azure OpenAI or OpenAI. False to use OpenAI, True to use Azure OpenAI\n",
    "var useAzureOpenAI = true;\n",
    "\n",
    "// Create a new Semantic Kernel instance\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    Console.WriteLine(\"Using Azure OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddAzureOpenAIChatCompletion(\n",
    "            deploymentName: azureOpenAIModelDeploymentName,\n",
    "            endpoint: azureOpenAIEndpoint,\n",
    "            apiKey: azureOpenAIAPIKey)\n",
    "        .Build();\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"Using OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddOpenAIChatCompletion(\n",
    "            modelId: openAIModelId,\n",
    "            apiKey: openAIAPIKey)\n",
    "        .Build();\n",
    "}\n",
    "\n",
    "var chatCompletionService = semanticKernel.Services.GetRequiredService<IChatCompletionService>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Chain of Thought Reasoning for Decision Intelligence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"The happiness of your life depends upon the quality of your thoughts.\" \n",
    ">\n",
    "> -- <cite>Marcus Aurelius (Roman emperor, philosopher)</cite>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most effective techniques to improve logic, reasoning and overall decision-making for most LLMs is to use \"Chain of Thought\" (CoT) techniques. The \"Chain of Thought\" approach helps by breaking down complex tasks into smaller steps, making it easier to solve problems without missing important details. It improves accuracy because each step is made clear to the LLM and helps avoid mistakes. This method also makes the thought process easier to understand and explain, allowing for easier corrections when something goes wrong. The approach is useful for handling difficult concepts and multi-step problems like math or logic, making things clearer and more manageable.\n",
    "\n",
    "The name of the \"Chain of Thought\" technique has been recently popularized by Generative AI. However, this technique is not new nor is it specific only to Generative AI models. Breaking down complex tasks into simpler more approachable steps and organizing thoughts has been used by decision-makers, professional services organizations and management consulting companies for quite some time. Prior to Generative AI, the concepts have been known as: \"structured thinking\", \"MECE framework\" (Mutually Exclusive, Collectively Exhaustive), and \"hypothesis-driven problem-solving\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, approach the problem with a simple Decision prompt technique. The system decisoin prompt will be set to basic & clear decision assistant persona instructions. While this decision prompt is simple, it is still quite effective to instruct the LLM model on how to approach the decision problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, the farmer needs to carefully plan the sequence of crossings to ensure that neither the goat nor the cabbage is eaten. Here's a step-by-step solution:\n",
      "\n",
      "---\n",
      "\n",
      "### Step-by-Step Instructions:\n",
      "\n",
      "1. **First Trip: Take the Goat Across**\n",
      "   - The farmer takes the goat across the river and leaves it on the far side.\n",
      "   - Now, the wolf and the cabbage are left together on the starting side, which is safe because the wolf does not eat the cabbage.\n",
      "\n",
      "2. **Second Trip: Go Back Alone**\n",
      "   - The farmer rows back to the starting side, leaving the goat alone on the far side.\n",
      "\n",
      "3. **Third Trip: Take the Wolf Across**\n",
      "   - The farmer takes the wolf across the river to the far side.\n",
      "   - However, the wolf and the goat cannot be left alone together, so the farmer **takes the goat back** with him to the starting side.\n",
      "\n",
      "4. **Fourth Trip: Take the Cabbage Across**\n",
      "   - The farmer takes the cabbage across the river to the far side and leaves it with the wolf.\n",
      "   - This is safe because the wolf does not eat the cabbage.\n",
      "\n",
      "5. **Fifth Trip: Go Back Alone**\n",
      "   - The farmer rows back to the starting side, leaving the wolf and the cabbage together on the far side.\n",
      "\n",
      "6. **Sixth Trip: Take the Goat Across Again**\n",
      "   - Finally, the farmer takes the goat across the river to the far side.\n",
      "\n",
      "---\n",
      "\n",
      "### Final Configuration:\n",
      "- All three items (the goat, the wolf, and the cabbage) are now safely on the far side of the river.\n",
      "- At no point were the wolf and the goat left alone together, nor were the goat and the cabbage left alone together.\n",
      "\n",
      "---\n",
      "\n",
      "### Key Principles:\n",
      "- The farmer must ensure that no two incompatible items (wolf and goat, or goat and cabbage) are left alone together.\n",
      "- The goat is transported multiple times to achieve this balance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemDecisionPrompt = \"\"\"\n",
    "You are a decision intelligence assistant. \n",
    "Provide structured, logical, and comprehensive advice.\n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var puzzlePrompt = \"\"\"\n",
    "A farmer is on one side of a river with a wolf, a goat, and a cabbage. \n",
    "When he is crossing the river in a boat, he can only take one item with him at a time. \n",
    "The wolf will eat the goat if left alone together, and the goat will eat the cabbage if left alone together. \n",
    "How can the farmer transport the goat across the river without it being eaten?\n",
    "\"\"\";\n",
    "\n",
    "// Build Chat History with system prompt and the puzzle prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemDecisionPrompt);\n",
    "chatHistory.AddUserMessage(puzzlePrompt);\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 1000, \n",
    "    Temperature = 0.3, \n",
    "    TopP = 1.0, \n",
    "    FrequencyPenalty = 0.0, \n",
    "    PresencePenalty = 0.0\n",
    "    };\n",
    "\n",
    "var decisionResponse = string.Empty;\n",
    "await foreach (var content in chatCompletionService.GetStreamingChatMessageContentsAsync(chatHistory, openAIPromptExecutionSettings))\n",
    "{\n",
    "    decisionResponse += content;\n",
    "    Console.Write(content);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's approach the same problem with a much more sophisticated \"Chain of Thought\" (CoT) system prompt to break the problem down and think about it more in depth. Notice that the prompt below is much more detailed in how the \"decision intelligence assistant\" should approach the problem, highlighting things it should or should not consider and the way it should arrive at the final answer. \n",
    "\n",
    "Chain of Thought (CoT) prompt instructions will vary depending on how the problem needs to be approached. It can include very specific decision framework instructions, systematic decision heuristics or management consulting best practices. In general, these detailed prompts result in the LLM providing more detail and usually better outcomes. However, there are a few drawbacks to overusing Chain of Thought (CoT):\n",
    "* A very long and detailed Chain of Thought (CoT) can confuse the LLM model, especially if the LLM model is smaller (i.e. GPT-4o-mini or Phi-4 etc.)\n",
    "* GenAI LLM models can hallucinate not just on output of answers. They can also hallucinate the Chain of Thought (CoT) they are describing in the final answer! This is a very sneaky way of potentially providing a confident answer paired with a confident approach (Chain of Thought) that the LLM may not even be using! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Step 1: Understand the Problem\n",
      "The farmer needs to transport a wolf, a goat, and a cabbage across a river using a boat that can carry only one item at a time. However, there are constraints:\n",
      "1. The wolf will eat the goat if left alone together.\n",
      "2. The goat will eat the cabbage if left alone together.\n",
      "3. The farmer must ensure that no eating occurs during the process.\n",
      "\n",
      "The goal is to determine a step-by-step strategy for the farmer to transport all three items safely across the river.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Break Down the Reasoning Process\n",
      "To solve this problem, we need to:\n",
      "1. Identify the constraints and ensure that at no point are the wolf and goat, or the goat and cabbage, left alone together.\n",
      "2. Use logical reasoning to determine the sequence of crossings that satisfies the constraints.\n",
      "3. Verify that the solution works and avoids any violations of the rules.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Explain Each Step\n",
      "Here’s the step-by-step solution:\n",
      "\n",
      "1. **First Crossing:** The farmer takes the goat across the river first.\n",
      "   - **Reasoning:** The goat is the critical item because it is at risk of being eaten by the wolf or eating the cabbage. By taking the goat first, the farmer ensures it is safe on the other side of the river.\n",
      "\n",
      "2. **Second Crossing:** The farmer goes back alone to the original side.\n",
      "   - **Reasoning:** The wolf and cabbage can safely remain together because neither will eat the other.\n",
      "\n",
      "3. **Third Crossing:** The farmer takes the wolf across the river.\n",
      "   - **Reasoning:** Now the farmer must transport the wolf, but he cannot leave the wolf and goat together on the far side. So, after dropping off the wolf, the farmer brings the goat back to the original side.\n",
      "\n",
      "4. **Fourth Crossing:** The farmer takes the cabbage across the river.\n",
      "   - **Reasoning:** The cabbage can now be safely left with the wolf on the far side because the wolf does not eat cabbage.\n",
      "\n",
      "5. **Fifth Crossing:** The farmer goes back alone to the original side.\n",
      "   - **Reasoning:** The goat is the only item left on the original side.\n",
      "\n",
      "6. **Sixth Crossing:** The farmer takes the goat across the river.\n",
      "   - **Reasoning:** Now all three items—the wolf, goat, and cabbage—are safely on the far side of the river, and no eating has occurred.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 4: Review the Thought Process\n",
      "Let’s verify:\n",
      "- At no point are the wolf and goat left alone together.\n",
      "- At no point are the goat and cabbage left alone together.\n",
      "- All items are successfully transported across the river.\n",
      "\n",
      "The solution satisfies all constraints and achieves the goal.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 5: Final Answer\n",
      "Using the Minto Pyramid Principle:\n",
      "\n",
      "**Main Point:** The farmer can safely transport the wolf, goat, and cabbage across the river by following a specific sequence of crossings.\n",
      "\n",
      "**Supporting Points:**\n",
      "1. First, take the goat across the river.\n",
      "2. Return alone and take the wolf across, then bring the goat back.\n",
      "3. Take the cabbage across the river.\n",
      "4. Finally, return alone and take the goat across.\n",
      "\n",
      "**Conclusion:** This sequence ensures that no eating occurs, and all items are safely transported."
     ]
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemPromptChainOfThought = \"\"\"\n",
    "You are a Decision Intelligence assistant designed to think through problems step-by-step using Chain-of-Thought (COT) prompting. \n",
    "Before providing any answer, you must: \n",
    "\n",
    "1) Understand the Problem: Carefully read and understand the user's question or request. \n",
    "\n",
    "2) Break Down the Reasoning Process: Outline the steps required to solve the problem or respond to the request logically and sequentially. Think aloud and describe each step in detail. \n",
    "Explain Each Step: Provide reasoning or calculations for each step, explaining how you arrive at each part of your answer. \n",
    "Provide structured, logical, and comprehensive advice. \n",
    "\n",
    "3) Review the Thought Process: Double-check the reasoning for errors or gaps before finalizing your response. \n",
    "Always aim to make your thought process transparent and logical.\n",
    "\n",
    "4) Arrive at the Final Answer: Only after completing all steps, provide the final answer or solution. \n",
    "\n",
    "5) Communicate the final decision using the Minto Pyramid Principle.\n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var puzzlePrompt = \"\"\"\n",
    "A farmer is on one side of a river with a wolf, a goat, and a cabbage. \n",
    "When he is crossing the river in a boat, he can only take one item with him at a time. \n",
    "The wolf will eat the goat if left alone together, and the goat will eat the cabbage if left alone together. \n",
    "How can the farmer transport the goat across the river without it being eaten?\n",
    "\"\"\";\n",
    "\n",
    "// Create a new chat history object using the new Chain of Thought system prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemPromptChainOfThought);\n",
    "chatHistory.AddUserMessage(puzzlePrompt);\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 1000, \n",
    "    Temperature = 0.3, \n",
    "    TopP = 1.0, \n",
    "    FrequencyPenalty = 0.0, \n",
    "    PresencePenalty = 0.0\n",
    "    };\n",
    "\n",
    "var decisionResponseChainOfThought = string.Empty;\n",
    "await foreach (var content in chatCompletionService.GetStreamingChatMessageContentsAsync(chatHistory, openAIPromptExecutionSettings))\n",
    "{\n",
    "    decisionResponseChainOfThought += content;\n",
    "    Console.Write(content);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Generative AI model has generated two different decision approaches to the same retirement decision question. An LLM can be used to decide which decision approach is of better quality. The evaluation could be done by another AI model or an AI model from different AI provider to reduce potential bias. \n",
    "\n",
    "After running the evaluation of the decision prompts below, notice the GenAI LLM model prefers the approach of the Chain of Thought (CoT) over the simple system prompt instruction. Furthermore, the AI model appreciates using the \"Decision Communication\" step with the applied Minto Pyramid.  \n",
    "\n",
    "> Note: When running the decision approach evaluation below, you may notice that sometimes Approach 1 is preferred. This happens as Approach 2 with Chain of Thought is considered verbose and not a clear as Approach 1 to the AI model.  In a real-world implementation, the prompt instruction will have this made very clear on what the criteria are. I specifically left that instruction out of the prompt to illustrate that even an AI model can vary it's preference!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Approaches Evaluation: \n",
      "### Evaluation of Approaches:\n",
      "\n",
      "#### Logical Reasoning of Approach:\n",
      "- **Approach 1:** The reasoning is sound and logically consistent. It clearly identifies the constraints (wolf-goat and goat-cabbage cannot be left alone) and provides a step-by-step solution that adheres to these constraints. Each step is justified, and the reasoning ensures that the problem is solved without any violations.\n",
      "- **Approach 2:** The reasoning is equally sound and logically consistent. It also identifies the constraints and provides a step-by-step solution. However, Approach 2 spends more time explicitly breaking down the reasoning process, including a verification step to ensure the solution works. This additional layer of explanation strengthens the logical reasoning.\n",
      "\n",
      "#### Detail of the Approach to the Decision:\n",
      "- **Approach 1:** The approach is detailed, providing a clear sequence of steps and explaining why each step is necessary. It also includes a summary of the final configuration and the key principles behind the solution. However, it does not explicitly verify the solution at the end, which would have added an extra layer of thoroughness.\n",
      "- **Approach 2:** This approach is slightly more detailed. It not only provides the step-by-step solution but also includes a structured breakdown of the reasoning process, a verification step, and a review of the thought process. It even uses the Minto Pyramid Principle to summarize the solution, which adds clarity and structure.\n",
      "\n",
      "#### Quality of Reasoning Communicated:\n",
      "- **Approach 1:** The reasoning is communicated clearly and concisely. The step-by-step instructions are easy to follow, and the explanation of key principles is helpful. However, the communication could have been enhanced by explicitly verifying the solution at the end.\n",
      "- **Approach 2:** The reasoning is communicated with exceptional clarity and depth. The structured breakdown of the problem, the explicit verification step, and the use of a summary framework (Minto Pyramid Principle) make the communication more comprehensive and polished. This approach is more thorough in ensuring the reader understands the solution and its correctness.\n",
      "\n",
      "---\n",
      "\n",
      "### Final Scores:\n",
      "- **Approach 1:** 8/10  \n",
      "  - Strengths: Clear and logical solution, detailed step-by-step instructions, and adherence to constraints.  \n",
      "  - Weaknesses: Lacks an explicit verification step and a structured summary of the reasoning process.\n",
      "\n",
      "- **Approach 2:** 10/10  \n",
      "  - Strengths: Exceptionally clear and thorough reasoning, detailed breakdown of the problem, inclusion of a verification step, and a well-structured summary.  \n",
      "  - Weaknesses: None apparent.  \n",
      "\n",
      "### Conclusion:\n",
      "While both approaches provide correct and logical solutions to the problem, Approach 2 stands out for its depth, structure, and quality of communication. It is the more comprehensive and polished response."
     ]
    }
   ],
   "source": [
    "var systemPromptEvaluateResponses = \"\"\"\n",
    "You are an assistant that is evaluating an approach response to a question.\n",
    "You will be provided with an important decision as well as two proposed approaches.\n",
    "The two approaches are labeled \"Approach 1\" and \"Approach 2\".\n",
    "\n",
    "Compare the two approaches and evaluate them based on their: \n",
    "logical reasoning of approach, detail of the approach to the decision and the quality the reasoning communicated. \n",
    "\n",
    "Create a final score between 1 and 10 for each approach based on the evaluation criteria.\n",
    "\"\"\";\n",
    "\n",
    "var decisionEvaluationTemplateApproaches = $\"\"\"\n",
    "Decision Scenario: \n",
    "{puzzlePrompt}\n",
    "------------------------------------------------\n",
    "Approach 1: \n",
    "{decisionResponse} \n",
    "End of Approach 1\n",
    "------------------------------------------------\n",
    "Approach 2: \n",
    "{decisionResponseChainOfThought} \n",
    "End of Approach 2\n",
    "\"\"\";\n",
    "\n",
    "// Create a new chat history object using the new Chain of Thought system prompt\n",
    "var chatHistoryApproachEvaluation = new ChatHistory();\n",
    "chatHistoryApproachEvaluation.AddSystemMessage(systemPromptEvaluateResponses);\n",
    "chatHistoryApproachEvaluation.AddUserMessage(decisionEvaluationTemplateApproaches);\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 2500, \n",
    "    Temperature = 0.3, \n",
    "    TopP = 1.0, \n",
    "    FrequencyPenalty = 0.0, \n",
    "    PresencePenalty = 0.0\n",
    "    };\n",
    "\n",
    "\n",
    "Console.WriteLine(\"Decision Approaches Evaluation: \");\n",
    "var evaluationResponseApproach1 = string.Empty;\n",
    "await foreach (var content in chatCompletionService.GetStreamingChatMessageContentsAsync(chatHistoryApproachEvaluation, openAIPromptExecutionSettings))\n",
    "{\n",
    "    evaluationResponseApproach1 += content;\n",
    "    Console.Write(content);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Collective Intelligence for Decision Intelligence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "#### Collective Intelligence - Pooling Wisdom of Multiple Opinions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you’ve hurt your leg playing a long season of football games. You have another football season quickly approaching and you would like to understand how long will it take to heal properly. Additionally, you would like to understand the optimal medical treatment to ensure you are ready at the start of the next football season. You decide to visit three different doctors for their medical opinions. You don’t want to rely on just one doctor because each professional might notice something the others miss. Each medical specialist may decide to recommend a different approach based on their expertise or their own experience treating leg injuries. After you receive opinions from three different specialists, you think about their recommendations and then formulate a path forward (decision) for a treatment plan for your leg. The final treatment plan could be a result a variety of factors. For example, it could be simple and all three doctors could recommend 4-6 weeks rest. Clearly in that case there is a consensus with three different doctors on the treatment approach. What if the doctors diverge in their opinions? What if 2 of 3 doctors recommend rest and a third recommends an additional procedure on top of rest? What if all three doctors opinions totally diverge? Now you have to personally judge those doctor opinions collectively or potentially weight one doctor's opinion more significantly than others. This scenario illustrates a simplified version of collective intelligence, where pooling diverse expert opinions often leads to a more informed and balanced decision.\n",
    "\n",
    "The idea of multiple experts arriving at a cohesive conclusion isn’t new. It has been demonstated that pooling the wisdom of multiple “opinions” can often outperform a single prediction. Those opinions don't have to be human experts. The opinions can be outcomes from a statistical model, a large survey, a machine learning model or Generative AI. You have probably have heard the terms: Wisdom of the Crowds, Collective Intelligence, Bootstrapping (technique in statistical analysis), Ensembling (Machine Learing) or Mixture of Experts (Generative AI). These are all similar techniques (with their own unique implementations) that derive of the core concept of \"pooling wisdom of multiple opinions\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-SelfConsistency.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of \"Wisdom of the Crowds\" at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Wisdom of the Crowds\" can scale well beyond just a few doctor's opinions. In the examples below, note the number of samples collected for each situation is much greater than just a few doctors. In fact, the amount of samples collected can be in the hundreds and the Collective Intelligence power can hold true. \n",
    "\n",
    "**Francis Galton’s Ox-Weighing Experiment (1906)** \n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-CollectiveIntelligence-OxWeight.png\"> \n",
    "\n",
    "Sir Francis Galton, an English statistician, collected 787 guesses from fairgoers trying to estimate the weight of an ox. The average guess was 1,197 pounds, and the actual weight of the ox turned out to be 1,198 pounds. To Galton’s surprise, the average of these guesses (1,197 pounds) came remarkably close to the ox’s actual weight (1,198 pounds)—off by a single pound, or less than 0.1%. That level of accuracy was notable because the crowd was composed of a mixed audience: farmers with relevant experience, but also onlookers, tradespeople, and curious fairgoers with no particular expertise.\n",
    "\n",
    "**Modern “Jelly Bean Jar” Contests**\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-CollectiveIntelligence-JellyBeans.png\">\n",
    "\n",
    "Many schools and charities run fundraisers where people pay to guess the number of jelly beans in a jar. It’s commonly observed that while individual guesses can be wildly off, the average of a sufficiently large group is typically within a small percentage (often under 5% error) of the true count. As an example, Michael Mauboussin ran an 2007 experiment where Mauboussin presented a jar of jelly beans to 73 Columbia Business School students. The students' guesses ranged from 250 to 4,100, with an average error of 62%. However, the group's average guess was 1,151, which represented only a 3% off the correct number. Only two students guessed better!\n",
    "\n",
    "The cool part of the “Jelly Bean Jar” experiment is that it is very approachable to run yourself. In fact, you can do this with Generative AI as well. \n",
    "\n",
    "A short (5 minute) YouTube video illustrates running this experiment with human opinions:  \n",
    "[![Jelly Bean Jar Experiment](https://img.youtube.com/vi/AuQdoAa2FUs/0.jpg)](https://www.youtube.com/watch?v=AuQdoAa2FUs)\n",
    "\n",
    "\n",
    "**Netflix Recommendation Algorithm Million Dollar Prize**\n",
    "\n",
    "In 2006, Netflix launched the million-dollar Netflix Prize competition, challenging participants to improve its movie recommendation algorithm (Cinematch) by at least 10 percent. Over three years, data scientists and researchers worldwide experimented with innovative approaches, culminating in 2009 when an ensemble team calling itself “BellKor’s Pragmatic Chaos” finally met the 10-percent threshold with 10.06%. This group had blended multiple models into a single “ensemble” algorithm that outperformed any single predictive approach. This demonstrated how synthesis of different predictions can be more powerful than one model alone. Although Netflix ultimately chose not to deploy the winning solution due to technical and privacy considerations, the competition is still regarded as a landmark moment in machine learning and collective problem-solving.  \n",
    "\n",
    "More information can be found here: https://en.wikipedia.org/wiki/Netflix_Prize \n",
    "\n",
    "**“Ask the Audience” on Who Wants to Be a Millionaire?**\n",
    "\n",
    "On the TV quiz show, contestants can use the “Ask the Audience” lifeline to poll the studio audience for the correct answer. Historical data shows that the audience collectively identifies the correct answer around 90% of the time, which is significantly more accurate than individual expert panels, or even the “Phone a Friend” lifeline.\n",
    "\n",
    "**The U.S. Navy’s Hunt for the Missing Submarine Scorpion (1968)**\n",
    "\n",
    "When the USS Scorpion, a nuclear-powered submarine, vanished in 1968, the Navy enlisted a broad range of specialists to harness their varied expertise and wisdom for a methodical search. By applying Bayesian statistical techniques to each person’s estimate of where the submarine might lie, they were able to synthesize these disparate perspectives into a single, remarkably accurate prediction. The team’s calculated guess put the submarine’s probable location just a few hundred yards from its actual resting place! This is a testament to the effectiveness of coalescing multiple expert viewpoints. This success with the USS Scorpion search later inspired more widespread use of Bayesian approaches for complex rescue and recovery operations, affirming the power of collective intelligence in high-stakes scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics Explains why Collective Intelligence Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to understand that Collective Intelligence mechanisms are rooted in several statistics principles. This allows you to set up Collective Intelligence parameters appropriately for decision situations. Furthermore, this allows you to perform math (quantitative analysis) in the Decision Intelligence Execution step. The key statistical principles of Collective Intelligence:  \n",
    "* **Average of Independent Predictions:** The average of many independent predictions, opinions or guesses will average itself out towards the true value. Each individual prediction can be assumed to have an error.  \n",
    "Therefore the formula is:  Prediction = True Value + Error.  \n",
    "As long as the errors are random, they will cancel each other out on average. \n",
    "* **Law of Large Numbers:** The more guesses you have, the more the random errors balance out, reducing the overall variance of the collective guess. Mathematically, if you have a large number of independent predictions, the average guess converges on the True Value. \n",
    "* **Central Limit Theorem:** The distribution of preductions will tend toward a bell curve (a normal distribution) around the Predicted True Value. When you take the average (mean) of a large sample from a sample distribution like this, it will often fall near the true population distribution. This happens more often in real-life than statistics courses lead on.  \n",
    "\n",
    "Statistics explaining Collective Intelligence (Wisdom of the Crowds) is greatly simplfied and there are things to consider when attempting to replicate this experiment with real-world decision situations:  \n",
    "\n",
    "* **Bias Matters:** Collective Intelligence works best when individual biases do not all tilt in the same direction. For example, if you only poll basketball players about height-related predictions, it may introduce a huge bias towards larger height in a single direction. \n",
    "\n",
    "* **Independence:** The group’s diversity and independence of guesses are critical. A group of people trained in the same way or over-influenced by each other’s guesses might show correlated errors, undermining the benefit of aggregation.\n",
    "\n",
    "* **Meaningful Sample Size:** The sampling error shrinks as you collect more predictions (guesses). Assume you have 𝑁 amount of independent predictions. If each prediction's random error in guessing has a standard deviation of 𝜎, then the standard error of the mean guess drops by about a factor of $\\sqrt{𝑁}$. What does this mean? The more samples you add, the more reduction of the error you will notice. Furthermore, you will notice a larger reduction in error with the first initial predictions than further predictions made. Saying it another way. For example, if you have a certain error from 10 samples and you want to reduce that prediction error by half you need a total of 40 samples. Conversely, if you have 100 samples and you want to reduce that prediction error by half you need a total of 400 samples! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Implementing Collective Intelligence with Generative AI "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
