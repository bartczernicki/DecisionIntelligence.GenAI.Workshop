{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;padding-right: 10px\" width =\"40px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/SemanticKernelLogo.png\">\n",
    "\n",
    "## Semantic Kernel - Prompt Engineering for Quality Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Intelligence applied in this module:  \n",
    "* Optimizing prompts for logic, reasoning and decisions\n",
    "* Examples of applying decision intelligence techniques in prompts and their output effect \n",
    "* Prompt techniques such as Chain of Thought to improve the quality of the decision reasoning and outcome \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, the Semantic Kernel ability to chat completion experience will be used to optimize system prompts (personas) and instructive prompts. No new specific Semantic Kernel functionality will be introduced. This module will focus on introducing decision intelligence prompting techniques.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Initialize Configuration Builder & Build the Semantic Kernel Orchestration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next two cells to:\n",
    "* Use the Configuration Builder to load the API secrets.  \n",
    "* Use the API configuration to build the Semantic Kernel orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 9.0.6</span></li><li><span>Microsoft.Extensions.Configuration.Json, 9.0.6</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import the required NuGet configuration packages\n",
    "#r \"nuget: Microsoft.Extensions.Configuration, 9.0.6\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 9.0.6\"\n",
    "\n",
    "using Microsoft.Extensions.Configuration.Json;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using System.IO;\n",
    "\n",
    "// Load the configuration settings from the local.settings.json and secrets.settings.json files\n",
    "// The secrets.settings.json file is used to store sensitive information such as API keys\n",
    "var configurationBuilder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"local.settings.json\", optional: true, reloadOnChange: true)\n",
    "    .AddJsonFile(\"secrets.settings.json\", optional: true, reloadOnChange: true);\n",
    "var config = configurationBuilder.Build();\n",
    "\n",
    "// IMPORTANT: You ONLY NEED either Azure OpenAI or OpenAI connectiopn info, not both.\n",
    "// Azure OpenAI Connection Info\n",
    "var azureOpenAIEndpoint = config[\"AzureOpenAI:Endpoint\"];\n",
    "var azureOpenAIAPIKey = config[\"AzureOpenAI:APIKey\"];\n",
    "var azureOpenAIModelDeploymentName = config[\"AzureOpenAI:ModelDeploymentName\"];\n",
    "var azureOpenAIReasoningEndpoint = config[\"AzureOpenAI:ReasoningEndpoint\"];\n",
    "var azureOpenAIReasoningAPIKey = config[\"AzureOpenAI:ReasoningAPIKey\"];\n",
    "var azureOpenAIReasoningModelDeploymentName = config[\"AzureOpenAI:ReasoningModelDeploymentName\"];\n",
    "// OpenAI Connection Info \n",
    "var openAIAPIKey = config[\"OpenAI:APIKey\"];\n",
    "var openAIModelId = config[\"OpenAI:ModelId\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.DependencyInjection, 9.0.6</span></li><li><span>Microsoft.SemanticKernel, 1.56.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI Service\r\n"
     ]
    }
   ],
   "source": [
    "// Install the required NuGet packages\n",
    "// Note: This also installs the Dependency Injection Package to retrieve the ChatCompletionService\n",
    "#r \"nuget: Microsoft.Extensions.DependencyInjection, 9.0.6\"\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.56\"\n",
    "\n",
    "using Microsoft.Extensions.DependencyInjection.Extensions;\n",
    "using Microsoft.Extensions.DependencyInjection;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "Kernel semanticKernel;\n",
    "\n",
    "// Set the flag to use Azure OpenAI or OpenAI. False to use OpenAI, True to use Azure OpenAI\n",
    "var useAzureOpenAI = true;\n",
    "\n",
    "// Create a new Semantic Kernel instance\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    Console.WriteLine(\"Using Azure OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddAzureOpenAIChatCompletion(\n",
    "            deploymentName: azureOpenAIModelDeploymentName,\n",
    "            endpoint: azureOpenAIEndpoint,\n",
    "            apiKey: azureOpenAIAPIKey)\n",
    "        .Build();\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"Using OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddOpenAIChatCompletion(\n",
    "            modelId: openAIModelId,\n",
    "            apiKey: openAIAPIKey)\n",
    "        .Build();\n",
    "}\n",
    "\n",
    "var chatCompletionService = semanticKernel.Services.GetRequiredService<IChatCompletionService>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Chain of Thought Reasoning for Decision Intelligence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìú **_\"The happiness of your life depends upon the quality of your thoughts.\"_**\n",
    ">\n",
    "> -- <cite>Marcus Aurelius (Roman emperor, philosopher)</cite>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most effective techniques to improve logic, reasoning and overall decision-making for most LLMs is to use \"Chain of Thought\" (CoT) techniques. The \"Chain of Thought\" approach helps by breaking down complex tasks into smaller steps, making it easier to solve problems without missing important details. It improves accuracy because each step is made clear to the LLM and helps avoid mistakes. This method also makes the thought process easier to understand and explain, allowing for easier corrections when something goes wrong. The approach is useful for handling difficult concepts and multi-step problems like math or logic, making things clearer and more manageable.\n",
    "\n",
    "The name of the \"Chain of Thought\" technique has been recently popularized by Generative AI. However, this technique is not new nor is it specific only to Generative AI models. Breaking down complex tasks into simpler more approachable steps and organizing thoughts has been used by decision-makers, professional services organizations and management consulting companies for quite some time. Prior to Generative AI, the concepts have been known as: \"structured thinking\", \"MECE framework\" (Mutually Exclusive, Collectively Exhaustive), and \"hypothesis-driven problem-solving\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, approach the problem with a simple Decision prompt technique. The system decisoin prompt will be set to basic & clear decision assistant persona instructions. While this decision prompt is simple, it is still quite effective to instruct the LLM model on how to approach the decision problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Problem Restatement\n",
       "\n",
       "- The farmer needs to transport a wolf, a goat, and a cabbage across a river.\n",
       "- The boat can only carry the farmer and one item at a time.\n",
       "- If left alone together:\n",
       "  - The wolf will eat the goat.\n",
       "  - The goat will eat the cabbage.\n",
       "- The goal: **Transport the goat across the river without it being eaten.**\n",
       "\n",
       "### Step-by-Step Solution\n",
       "\n",
       "#### 1. Analyze the Risks\n",
       "- The goat is at risk of being eaten by the wolf if left alone with it.\n",
       "- The goat will eat the cabbage if left alone with it.\n",
       "- The farmer must ensure that the goat is never left alone with the wolf or the cabbage.\n",
       "\n",
       "#### 2. Focus on the Goat\n",
       "- The question specifically asks about transporting the goat across the river without it being eaten.\n",
       "\n",
       "#### 3. Safe Sequence to Move the Goat\n",
       "\n",
       "**Step 1:**  \n",
       "- The farmer takes the goat across the river first.\n",
       "- **Left side:** Wolf, Cabbage  \n",
       "- **Right side:** Goat, Farmer\n",
       "\n",
       "**Step 2:**  \n",
       "- The farmer returns alone to the left side.\n",
       "- **Left side:** Wolf, Cabbage, Farmer  \n",
       "- **Right side:** Goat\n",
       "\n",
       "**Result:**  \n",
       "- The goat is now across the river, and at no point was it left alone with the wolf or the cabbage.\n",
       "\n",
       "### Key Points\n",
       "\n",
       "- The goat is never left alone with the wolf or the cabbage during this process.\n",
       "- The farmer must always supervise the goat when it is with either the wolf or the cabbage.\n",
       "\n",
       "### Summary Table\n",
       "\n",
       "| Step | Left Side         | Right Side     | Action                       |\n",
       "|------|-------------------|---------------|------------------------------|\n",
       "| 1    | Wolf, Cabbage     | Goat, Farmer  | Farmer takes goat across     |\n",
       "| 2    | Wolf, Cabbage, Farmer | Goat      | Farmer returns alone         |\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "**To transport the goat across the river without it being eaten, the farmer should take the goat across first and return alone.** This ensures the goat is never left alone with the wolf or the cabbage."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemDecisionPrompt = \"\"\"\n",
    "You are a decision intelligence assistant. \n",
    "Provide structured, logical, and comprehensive advice.\n",
    "\n",
    "Output Format Instructions:\n",
    "When generating Markdown, do not use any headings higher than ###. \n",
    "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
    "All top-level section headers should start at ### or lower. \n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var puzzlePrompt = \"\"\"\n",
    "A farmer is on one side of a river with a wolf, a goat, and a cabbage. \n",
    "When he is crossing the river in a boat, he can only take one item with him at a time. \n",
    "The wolf will eat the goat if left alone together, and the goat will eat the cabbage if left alone together. \n",
    "How can the farmer transport the goat across the river without it being eaten?\n",
    "\"\"\";\n",
    "\n",
    "// Build Chat History with system prompt and the puzzle prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemDecisionPrompt);\n",
    "chatHistory.AddUserMessage(puzzlePrompt);\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 1000, \n",
    "    Temperature = 0.3, \n",
    "    TopP = 1.0, \n",
    "    FrequencyPenalty = 0.0, \n",
    "    PresencePenalty = 0.0\n",
    "    };\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var decisionResponse = await chatCompletionService.GetChatMessageContentAsync(chatHistory, openAIPromptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "decisionResponse.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's approach the same problem with a much more sophisticated \"Chain of Thought\" (CoT) system prompt to break the problem down and think about it more in depth. Notice that the prompt below is much more detailed in how the \"decision intelligence assistant\" should approach the problem, highlighting things it should or should not consider and the way it should arrive at the final answer. \n",
    "\n",
    "Chain of Thought (CoT) prompt instructions will vary depending on how the problem needs to be approached. It can include very specific decision framework instructions, systematic decision heuristics or management consulting best practices. In general, these detailed prompts result in the LLM providing more detail and usually better outcomes. However, there are a few drawbacks to overusing Chain of Thought (CoT):\n",
    "* A very long and detailed Chain of Thought (CoT) can confuse the LLM model, especially if the LLM model is smaller (i.e. GPT-4o-mini or Phi-4 etc.)\n",
    "* GenAI LLM models can hallucinate not just on output of answers. They can also hallucinate the Chain of Thought (CoT) they are describing in the final answer! This is a very sneaky way of potentially providing a confident answer paired with a confident approach (Chain of Thought) that the LLM may not even be using! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Understanding the Problem\n",
       "\n",
       "The farmer needs to transport a wolf, a goat, and a cabbage across a river. He can only take one item at a time in his boat. There are two critical constraints:\n",
       "- If the wolf and goat are left alone together, the wolf will eat the goat.\n",
       "- If the goat and cabbage are left alone together, the goat will eat the cabbage.\n",
       "\n",
       "The question specifically asks: **How can the farmer transport the goat across the river without it being eaten?**\n",
       "\n",
       "### Breaking Down the Reasoning Process\n",
       "\n",
       "Let's clarify the problem:\n",
       "- The farmer starts with all three items (wolf, goat, cabbage) on one side of the river.\n",
       "- He wants to take the goat across first.\n",
       "- We need to ensure that, at no point, the goat is left alone with the wolf or the cabbage on either side without the farmer present.\n",
       "\n",
       "Let's analyze the possible outcomes step by step:\n",
       "\n",
       "#### Step 1: Farmer takes the goat across first.\n",
       "- Left side: Wolf, Cabbage\n",
       "- Right side: Goat, Farmer\n",
       "\n",
       "Is this safe?\n",
       "- On the left side, wolf and cabbage are alone. The wolf does not eat the cabbage, so this is safe.\n",
       "- On the right side, goat is with the farmer, so it's safe.\n",
       "\n",
       "#### Step 2: Farmer returns alone to the left side.\n",
       "- Left side: Wolf, Cabbage, Farmer\n",
       "- Right side: Goat\n",
       "\n",
       "Is this safe?\n",
       "- On the left side, wolf and cabbage are alone with the farmer, so it's safe.\n",
       "- On the right side, goat is alone. Is this safe? Yes, because the goat is not with the cabbage or wolf.\n",
       "\n",
       "### Review the Thought Process\n",
       "\n",
       "- The key risk is leaving the goat with either the wolf or the cabbage without the farmer.\n",
       "- By taking the goat first, the wolf and cabbage are left together, which is safe.\n",
       "- When the farmer returns alone, the goat is alone on the other side, which is also safe.\n",
       "\n",
       "### Arriving at the Final Answer\n",
       "\n",
       "#### Minto Pyramid Principle Communication\n",
       "\n",
       "**Main Point:**  \n",
       "The farmer can safely transport the goat across the river first without it being eaten.\n",
       "\n",
       "**Supporting Points:**  \n",
       "- Leaving the wolf and cabbage together is safe, as they do not harm each other.\n",
       "- The goat is never left alone with either the wolf or the cabbage without the farmer present.\n",
       "\n",
       "**Details:**  \n",
       "1. The farmer takes the goat across the river and leaves it on the other side.\n",
       "2. The farmer returns alone to the original side.\n",
       "\n",
       "This sequence ensures the goat is not eaten during the initial crossing."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemPromptChainOfThought = \"\"\"\n",
    "You are a Decision Intelligence assistant designed to think through problems step-by-step using Chain-of-Thought (CoT) prompting. \n",
    "Before providing any answer, you must: \n",
    "\n",
    "1) Understand the Problem: Carefully read and understand the user's question or request. \n",
    "\n",
    "2) Break Down the Reasoning Process: Outline the steps required to solve the problem or respond to the request logically and sequentially. Think aloud and describe each step in detail. \n",
    "Explain Each Step: Provide reasoning or calculations for each step, explaining how you arrive at each part of your answer. \n",
    "Provide structured, logical, and comprehensive advice. \n",
    "\n",
    "3) Review the Thought Process: Double-check the reasoning for errors or gaps before finalizing your response. \n",
    "Always aim to make your thought process transparent and logical.\n",
    "\n",
    "4) Arrive at the Final Answer: Only after completing all steps, provide the final answer or solution. \n",
    "\n",
    "5) Communicate the final decision using the Minto Pyramid Principle. \n",
    "\n",
    "Output Format Instructions:\n",
    "When generating Markdown, do not use any headings higher than ###. \n",
    "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
    "All top-level section headers should start at ### or lower. \n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var puzzlePrompt = \"\"\"\n",
    "A farmer is on one side of a river with a wolf, a goat, and a cabbage. \n",
    "When he is crossing the river in a boat, he can only take one item with him at a time. \n",
    "The wolf will eat the goat if left alone together, and the goat will eat the cabbage if left alone together. \n",
    "How can the farmer transport the goat across the river without it being eaten?\n",
    "\"\"\";\n",
    "\n",
    "// Create a new chat history object using the new Chain of Thought system prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemPromptChainOfThought);\n",
    "chatHistory.AddUserMessage(puzzlePrompt);\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 1000, \n",
    "    Temperature = 0.3, \n",
    "    TopP = 1.0, \n",
    "    FrequencyPenalty = 0.0, \n",
    "    PresencePenalty = 0.0\n",
    "    };\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var decisionResponseChainOfThought = await chatCompletionService.GetChatMessageContentAsync(chatHistory, openAIPromptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "decisionResponseChainOfThought.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Generative AI model has generated two different decision approaches to the same retirement decision question. An LLM can be used to decide which decision approach is of better quality. The evaluation could be done by another AI model or an AI model from different AI provider to reduce potential bias. \n",
    "\n",
    "After running the evaluation of the decision prompts below, notice the GenAI LLM model prefers the approach of the Chain of Thought (CoT) over the simple system prompt instruction. Furthermore, the AI model appreciates using the \"Decision Communication\" step with the applied Minto Pyramid.  \n",
    "\n",
    "> üìù **Note:** When executing the decision approach evaluation below, you may notice that sometimes Approach 1 is preferred. This happens as Approach 2 with Chain of Thought is considered verbose and not a clear as Approach 1 to the AI model.  In a real-world implementation, the prompt instruction will have this made very clear on what the criteria are. I specifically left that instruction out of the prompt to illustrate that even an AI model can vary it's preference!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Decision Approaches Evaluation: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Evaluation of Approaches**\n",
       "\n",
       "---\n",
       "\n",
       "### Approach 1\n",
       "\n",
       "**Logical Structured Reasoning:**\n",
       "- The approach is logically structured, starting with a restatement of the problem, followed by risk analysis, focus on the goat, and a clear step-by-step solution.\n",
       "- The reasoning is methodical and ensures that all constraints are considered.\n",
       "- The use of a summary table adds clarity and reinforces the steps.\n",
       "\n",
       "**Detail of the Approach:**\n",
       "- The approach details the risks, the sequence of actions, and explicitly states the state of each side after every move.\n",
       "- It highlights why the goat is safe at each stage.\n",
       "- The summary table is a helpful visual aid that makes the solution easy to follow.\n",
       "\n",
       "**Quality of Communication:**\n",
       "- The explanation is clear, concise, and well-organized.\n",
       "- The use of headings and bullet points enhances readability.\n",
       "- The conclusion succinctly summarizes the solution.\n",
       "\n",
       "**Score: 10/10**\n",
       "\n",
       "---\n",
       "\n",
       "### Approach 2\n",
       "\n",
       "**Logical Structured Reasoning:**\n",
       "- The approach is logically sound and follows a clear step-by-step analysis.\n",
       "- It restates the problem and constraints, then walks through the solution, checking for safety at each step.\n",
       "- It includes a review of the thought process and uses the Minto Pyramid Principle for structured communication.\n",
       "\n",
       "**Detail of the Approach:**\n",
       "- The approach provides a detailed breakdown of each step, including the rationale for why each configuration is safe.\n",
       "- It checks the safety of both sides after each move.\n",
       "- However, it lacks a summary table or visual aid, which could have further clarified the steps.\n",
       "\n",
       "**Quality of Communication:**\n",
       "- The explanation is thorough and well-structured, with clear headings and logical flow.\n",
       "- The use of the Minto Pyramid Principle is a nice touch, summarizing the main point and supporting details.\n",
       "- The answer is slightly more verbose than necessary, but still clear.\n",
       "\n",
       "**Score: 9/10**\n",
       "\n",
       "---\n",
       "\n",
       "## Final Scores\n",
       "\n",
       "- **Approach 1:** 10/10\n",
       "- **Approach 2:** 9/10\n",
       "\n",
       "**Summary:**  \n",
       "Both approaches are strong, but Approach 1 edges ahead due to its succinctness, clear risk analysis, and the inclusion of a summary table that visually reinforces the solution. Approach 2 is also well-reasoned and communicates clearly, but could benefit from a more concise summary or visual aid."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var systemPromptEvaluateResponses = \"\"\"\n",
    "You are an assistant that is evaluating an approach response to a question.\n",
    "You will be provided with an important decision as well as two proposed approaches.\n",
    "The two approaches are labeled \"Approach 1\" and \"Approach 2\".\n",
    "\n",
    "Compare the two approaches and evaluate them based on their: \n",
    "Logical structured reasoning of approach, detail of the approach to the decision and the quality the communication. \n",
    "\n",
    "Create a final score between 1 and 10 for each approach based on the evaluation criteria.\n",
    "\"\"\";\n",
    "\n",
    "var decisionEvaluationTemplateApproaches = $\"\"\"\n",
    "Decision Scenario: \n",
    "{puzzlePrompt}\n",
    "------------------------------------------------\n",
    "Approach 1: \n",
    "{decisionResponse.Content} \n",
    "End of Approach 1\n",
    "------------------------------------------------\n",
    "Approach 2: \n",
    "{decisionResponseChainOfThought.Content} \n",
    "End of Approach 2\n",
    "\"\"\";\n",
    "\n",
    "// Create a new chat history object using the new Chain of Thought system prompt\n",
    "var chatHistoryApproachEvaluation = new ChatHistory();\n",
    "chatHistoryApproachEvaluation.AddSystemMessage(systemPromptEvaluateResponses);\n",
    "chatHistoryApproachEvaluation.AddUserMessage(decisionEvaluationTemplateApproaches);\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 2500, \n",
    "    Temperature = 0.3, \n",
    "    TopP = 1.0, \n",
    "    FrequencyPenalty = 0.0, \n",
    "    PresencePenalty = 0.0\n",
    "    };\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var evaluationResponseApproach1 = await chatCompletionService.GetChatMessageContentAsync(chatHistoryApproachEvaluation, openAIPromptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "\"### Decision Approaches Evaluation: \".DisplayAs(\"text/markdown\");\n",
    "evaluationResponseApproach1.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the output section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Collective Intelligence for Decision Intelligence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "#### Collective Intelligence - Pooling Wisdom of Multiple Opinions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìú **_\"The four conditions that characterize wise crowds: diversity of opinion, independence, decentralization, and aggregation.\"_**\n",
    ">\n",
    "> -- <cite>James Surowiecki (American journalist, author of The Wisdom of Crowds, and former columnist for The New Yorker)</cite> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you‚Äôve hurt your leg playing a long season of football games. You have another football season quickly approaching and you would like to understand how long will it take to heal properly. Additionally, you would like to understand the optimal medical treatment to ensure you are ready at the start of the next football season. You decide to visit three different doctors for their medical opinions. You don‚Äôt want to rely on just one doctor because each professional might notice something the others miss. Each medical specialist may decide to recommend a different approach based on their expertise or their own experience treating leg injuries. After you receive opinions from three different specialists, you think about their recommendations and then formulate a path forward (decision) for a treatment plan for your leg. The final treatment plan could be a result a variety of factors. For example, it could be simple and all three doctors could recommend 4-6 weeks rest. Clearly in that case there is a consensus with three different doctors on the treatment approach. What if the doctors diverge in their opinions? What if 2 of 3 doctors recommend rest and a third recommends an additional procedure on top of rest? What if all three doctors opinions totally diverge? Now you have to personally judge those doctor opinions collectively or potentially weight one doctor's opinion more significantly than others. This scenario illustrates a simplified version of collective intelligence, where pooling diverse expert opinions often leads to a more informed and balanced decision.\n",
    "\n",
    "The idea of multiple experts arriving at a cohesive conclusion isn‚Äôt new. It has been demonstated that pooling the wisdom of multiple ‚Äúopinions‚Äù can often outperform a single prediction. Those opinions don't have to be human experts. The opinions can be outcomes from a statistical model, a large survey, a machine learning model or Generative AI. You have probably have heard the terms: Wisdom of the Crowds, Collective Intelligence, Bootstrapping (technique in statistical analysis), Ensembling (Machine Learing) or Mixture of Experts (Generative AI). These are all similar techniques (with their own unique implementations) that derive of the core concept of \"pooling wisdom of multiple opinions\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-SelfConsistency.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of \"Wisdom of the Crowds\" at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Wisdom of the Crowds\" can scale well beyond just a few doctor's opinions. In the examples below, note the number of samples collected for each situation is much greater than just a few doctors. In fact, the amount of samples collected can be in the hundreds and the Collective Intelligence power can hold true. \n",
    "\n",
    "**Francis Galton‚Äôs Ox-Weighing Experiment (1906)** \n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-CollectiveIntelligence-OxWeight.png\"> \n",
    "\n",
    "Sir Francis Galton, an English statistician, collected 787 guesses from fairgoers trying to estimate the weight of an ox. The average guess was 1,197 pounds, and the actual weight of the ox turned out to be 1,198 pounds. To Galton‚Äôs surprise, the average of these guesses (1,197 pounds) came remarkably close to the ox‚Äôs actual weight (1,198 pounds)‚Äîoff by a single pound, or less than 0.1%. That level of accuracy was notable because the crowd was composed of a mixed audience: farmers with relevant experience, but also onlookers, tradespeople, and curious fairgoers with no particular expertise.\n",
    "\n",
    "**Modern ‚ÄúJelly Bean Jar‚Äù Contests**\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-CollectiveIntelligence-JellyBeans.png\">\n",
    "\n",
    "Many schools and charities run fundraisers where people pay to guess the number of jelly beans in a jar. It‚Äôs commonly observed that while individual guesses can be wildly off, the average of a sufficiently large group is typically within a small percentage (often under 5% error) of the true count. As an example, Michael Mauboussin ran an 2007 experiment where Mauboussin presented a jar of jelly beans to 73 Columbia Business School students. The students' guesses ranged from 250 to 4,100, with an average error of 62%. However, the group's average guess was 1,151, which represented only a 3% off the correct number. Only two students guessed better!\n",
    "\n",
    "The cool part of the ‚ÄúJelly Bean Jar‚Äù experiment is that it is very approachable to run yourself. In fact, you can do this with Generative AI as well. \n",
    "\n",
    "A short (5 minute) YouTube video illustrates running this experiment with human opinions:  \n",
    "[![Jelly Bean Jar Experiment](https://img.youtube.com/vi/AuQdoAa2FUs/0.jpg)](https://www.youtube.com/watch?v=AuQdoAa2FUs)\n",
    "\n",
    "\n",
    "**Netflix Recommendation Algorithm Million Dollar Prize**\n",
    "\n",
    "In 2006, Netflix launched the million-dollar Netflix Prize competition, challenging participants to improve its movie recommendation algorithm (Cinematch) by at least 10 percent. Over three years, data scientists and researchers worldwide experimented with innovative approaches, culminating in 2009 when an ensemble team calling itself ‚ÄúBellKor‚Äôs Pragmatic Chaos‚Äù finally met the 10-percent threshold with 10.06%. This group had blended multiple models into a single ‚Äúensemble‚Äù algorithm that outperformed any single predictive approach. This demonstrated how synthesis of different predictions can be more powerful than one model alone. Although Netflix ultimately chose not to deploy the winning solution due to technical and privacy considerations, the competition is still regarded as a landmark moment in machine learning and collective problem-solving.  \n",
    "\n",
    "More information can be found here: https://en.wikipedia.org/wiki/Netflix_Prize \n",
    "\n",
    "**‚ÄúAsk the Audience‚Äù on Who Wants to Be a Millionaire?**\n",
    "\n",
    "On the TV quiz show, contestants can use the ‚ÄúAsk the Audience‚Äù lifeline to poll the studio audience for the correct answer. Historical data shows that the audience collectively identifies the correct answer around 90% of the time, which is significantly more accurate than individual expert panels, or even the ‚ÄúPhone a Friend‚Äù lifeline.\n",
    "\n",
    "**The U.S. Navy‚Äôs Hunt for the Missing Submarine Scorpion (1968)**\n",
    "\n",
    "When the USS Scorpion, a nuclear-powered submarine, vanished in 1968, the Navy enlisted a broad range of specialists to harness their varied expertise and wisdom for a methodical search. By applying Bayesian statistical techniques to each person‚Äôs estimate of where the submarine might lie, they were able to synthesize these disparate perspectives into a single, remarkably accurate prediction. The team‚Äôs calculated guess put the submarine‚Äôs probable location just a few hundred yards from its actual resting place! This is a testament to the effectiveness of coalescing multiple expert viewpoints. This success with the USS Scorpion search later inspired more widespread use of Bayesian approaches for complex rescue and recovery operations, affirming the power of collective intelligence in high-stakes scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics Explains why Collective Intelligence Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to understand that Collective Intelligence mechanisms are rooted in several statistics principles. This allows you to set up Collective Intelligence parameters appropriately for decision situations. Furthermore, this allows you to perform math (quantitative analysis) in the Decision Intelligence Execution step. The key statistical principles of Collective Intelligence:  \n",
    "* **Average of Independent Predictions:** The average of many independent predictions, opinions or guesses will average itself out towards the true value. Each individual prediction can be assumed to have an error.  \n",
    "Therefore the formula is:  Prediction = True Value + Error.  \n",
    "As long as the errors are random, they will cancel each other out on average. \n",
    "* **Law of Large Numbers:** The more guesses you have, the more the random errors balance out, reducing the overall variance of the collective guess. Mathematically, if you have a large number of independent predictions, the average guess converges on the True Value. \n",
    "* **Central Limit Theorem:** The distribution of preductions will tend toward a bell curve (a normal distribution) around the Predicted True Value. When you take the average (mean) of a large sample from a sample distribution like this, it will often fall near the true population distribution. This happens more often in real-life than statistics courses lead on.  \n",
    "\n",
    "Statistics explaining Collective Intelligence (Wisdom of the Crowds) is greatly simplfied and there are things to consider when attempting to replicate this experiment with real-world decision situations:  \n",
    "\n",
    "* **Bias Matters:** Collective Intelligence works best when individual biases do not all tilt in the same direction. For example, if you only poll basketball players about height-related predictions, it may introduce a huge bias towards larger height in a single direction. \n",
    "\n",
    "* **Independence:** The group‚Äôs diversity and independence of guesses are critical. A group of people trained in the same way or over-influenced by each other‚Äôs guesses might show correlated errors, undermining the benefit of aggregation.\n",
    "\n",
    "* **Meaningful Sample Size:** The sampling error shrinks as you collect more predictions (guesses). Assume you have ùëÅ amount of independent predictions. If each prediction's random error in guessing has a standard deviation of ùúé, then the standard error of the mean guess drops by about a factor of $\\sqrt{ùëÅ}$. What does this mean? The more samples you add, the more reduction of the error you will notice. Furthermore, you will notice a larger reduction in error with the first initial predictions than further predictions made. Saying it another way. For example, if you have a certain error from 10 samples and you want to reduce that prediction error by half you need a total of 40 samples. Conversely, if you have 100 samples and you want to reduce that prediction error by half you need a total of 400 samples! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Implementing Collective Intelligence with Generative AI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in Progress - AI with Collective Intelligence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemDecisionPrompt = \"\"\"\n",
    "You are a decision intelligence assistant. \n",
    "Provide structured, logical, and comprehensive advice.\n",
    "\n",
    "Output Format Instructions:\n",
    "When generating Markdown, do not use any headings higher than ###. \n",
    "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
    "All top-level section headers should start at ### or lower. \n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var collectiveIntelligencePrompt = \"\"\"\n",
    "In this image there is a picture of a jar full to the top with jelly beans.\n",
    "The jelly beans are of different colors and sizes, but they are all roughly the same size.\n",
    "This image was taken from a video and includes other people and surroundings to provide a perspective of size of the jar.  \n",
    "\n",
    "Esimtate the number of jelly beans in the jar. \n",
    "Think through the estimate clearly using all the available information in the image.\n",
    "\n",
    "Provide only a single number as the answer.\n",
    "\"\"\";\n",
    "\n",
    "// Uri of a single image of a jar of jelly beans\n",
    "Uri githubImageUri1 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/JellyBeans1.png\");\n",
    "\n",
    "// Build Chat History with system prompt and the puzzle prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemDecisionPrompt);\n",
    "chatHistory.Add(\n",
    "    new() {\n",
    "        Role = AuthorRole.User,\n",
    "        Items = [\n",
    "            new TextContent { Text = collectiveIntelligencePrompt },\n",
    "            new ImageContent { Uri = githubImageUri1 }\n",
    "        ]\n",
    "    });\n",
    "\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 1000, \n",
    "    Temperature = 0.3, \n",
    "    TopP = 1.0, \n",
    "    };\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var decisionResponse = await chatCompletionService.GetChatMessageContentAsync(chatHistory, openAIPromptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "decisionResponse.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "320"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemDecisionPrompt = \"\"\"\n",
    "You are a decision intelligence assistant. \n",
    "Provide structured, logical, and comprehensive advice.\n",
    "\n",
    "Output Format Instructions:\n",
    "When generating Markdown, do not use any headings higher than ###. \n",
    "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
    "All top-level section headers should start at ### or lower. \n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var collectiveIntelligencePrompt = \"\"\"\n",
    "You are provided with several images of a jar full to the top with jelly beans. \n",
    "The jelly beans are of different colors and sizes, but they are all roughly the same size.\n",
    "The images were taken from a video and include other people and surroundings to provide a perspective of size of the jar.\n",
    "The images provided are the same exact jar, but from different angles and distances. \n",
    "\n",
    "Esimtate the number of jelly beans in the jar. \n",
    "Think through the estimate clearly using all the available information in the image.\n",
    "\n",
    "Provide only a single number as the answer.\n",
    "\"\"\";\n",
    "\n",
    "// Uri of a single image of a jar of jelly beans\n",
    "Uri githubImageUri1 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/JellyBeans1.png\");\n",
    "Uri githubImageUri2 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/JellyBeans2.png\");\n",
    "Uri githubImageUri3 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/JellyBeans3.png\");\n",
    "Uri githubImageUri4 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/JellyBeans4.png\");\n",
    "Uri githubImageUri5 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/JellyBeans5.png\");\n",
    "\n",
    "\n",
    "// Build Chat History with system prompt and the puzzle prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemDecisionPrompt);\n",
    "chatHistory.Add(\n",
    "    new() {\n",
    "        Role = AuthorRole.User,\n",
    "        Items = [\n",
    "            new TextContent { Text = collectiveIntelligencePrompt },\n",
    "            new ImageContent { Uri = githubImageUri1 },\n",
    "            new ImageContent { Uri = githubImageUri2 },\n",
    "            new ImageContent { Uri = githubImageUri3 },\n",
    "            new ImageContent { Uri = githubImageUri4 },\n",
    "            new ImageContent { Uri = githubImageUri5 }\n",
    "        ]\n",
    "    });\n",
    "\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 1000, \n",
    "    Temperature = 0.3, \n",
    "    TopP = 1.0, \n",
    "    };\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var decisionResponse = await chatCompletionService.GetChatMessageContentAsync(chatHistory, openAIPromptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "decisionResponse.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
