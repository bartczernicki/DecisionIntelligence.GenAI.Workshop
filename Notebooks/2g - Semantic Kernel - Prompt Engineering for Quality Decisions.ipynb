{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/SemanticKernelLogo.png\" width=\"40px\" style=\"margin-right: 10px;\">\n",
    "  <span style=\"font-size: 1.5em; font-weight: bold;\">Semantic Kernel - Prompt Engineering for Quality Decisions</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Intelligence applied in this module:  \n",
    "* Optimizing prompts for logic, reasoning and decisions\n",
    "* Examples of applying decision intelligence techniques in prompts and their output effect \n",
    "* Prompt techniques such as Chain of Thought to improve the quality of the decision reasoning and outcome \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, the Semantic Kernel ability to chat completion experience will be used to optimize system prompts (personas) and instructive prompts. No new specific Semantic Kernel functionality will be introduced. This module will focus on introducing decision intelligence prompting techniques.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Initialize Configuration Builder & Build the Semantic Kernel Orchestration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next two cells to:\n",
    "* Use the Configuration Builder to load the API secrets.  \n",
    "* Use the API configuration to build the Semantic Kernel orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.Configuration, 9.0.9</span></li><li><span>Microsoft.Extensions.Configuration.Json, 9.0.9</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import the required NuGet configuration packages\n",
    "#r \"nuget: Microsoft.Extensions.Configuration, 9.0.9\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 9.0.9\"\n",
    "\n",
    "using Microsoft.Extensions.Configuration.Json;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using System.IO;\n",
    "\n",
    "// Load the configuration settings from the local.settings.json and secrets.settings.json files\n",
    "// The secrets.settings.json file is used to store sensitive information such as API keys\n",
    "var configurationBuilder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"local.settings.json\", optional: true, reloadOnChange: true)\n",
    "    .AddJsonFile(\"secrets.settings.json\", optional: true, reloadOnChange: true);\n",
    "var config = configurationBuilder.Build();\n",
    "\n",
    "// IMPORTANT: You ONLY NEED either Azure OpenAI or OpenAI connectiopn info, not both.\n",
    "// Azure OpenAI Connection Info\n",
    "var azureOpenAIEndpoint = config[\"AzureOpenAI:Endpoint\"];\n",
    "var azureOpenAIAPIKey = config[\"AzureOpenAI:APIKey\"];\n",
    "var azureOpenAIModelDeploymentName = config[\"AzureOpenAI:ModelDeploymentName\"];\n",
    "var azureOpenAIReasoningEndpoint = config[\"AzureOpenAI:ReasoningEndpoint\"];\n",
    "var azureOpenAIReasoningAPIKey = config[\"AzureOpenAI:ReasoningAPIKey\"];\n",
    "var azureOpenAIReasoningModelDeploymentName = config[\"AzureOpenAI:ReasoningModelDeploymentName\"];\n",
    "// OpenAI Connection Info \n",
    "var openAIAPIKey = config[\"OpenAI:APIKey\"];\n",
    "var openAIModelId = config[\"OpenAI:ModelId\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Extensions.DependencyInjection, 9.0.9</span></li><li><span>Microsoft.SemanticKernel, 1.65.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI Service\n"
     ]
    }
   ],
   "source": [
    "// Install the required NuGet packages\n",
    "// Note: This also installs the Dependency Injection Package to retrieve the ChatCompletionService\n",
    "#r \"nuget: Microsoft.Extensions.DependencyInjection, 9.0.9\"\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.65.0\"\n",
    "\n",
    "using Microsoft.Extensions.DependencyInjection.Extensions;\n",
    "using Microsoft.Extensions.DependencyInjection;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.AzureOpenAI;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "Kernel semanticKernel;\n",
    "\n",
    "// Set the flag to use Azure OpenAI or OpenAI. False to use OpenAI, True to use Azure OpenAI\n",
    "var useAzureOpenAI = true;\n",
    "\n",
    "// Create a new Semantic Kernel instance\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    Console.WriteLine(\"Using Azure OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddAzureOpenAIChatCompletion(\n",
    "            deploymentName: azureOpenAIModelDeploymentName,\n",
    "            endpoint: azureOpenAIEndpoint,\n",
    "            apiKey: azureOpenAIAPIKey)\n",
    "        .Build();\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"Using OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddOpenAIChatCompletion(\n",
    "            modelId: openAIModelId,\n",
    "            apiKey: openAIAPIKey)\n",
    "        .Build();\n",
    "}\n",
    "\n",
    "var chatCompletionService = semanticKernel.Services.GetRequiredService<IChatCompletionService>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Chain of Thought Reasoning for Decision Intelligence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📜 **_\"The happiness of your life depends upon the quality of your thoughts.\"_**\n",
    ">\n",
    "> -- <cite>Marcus Aurelius (Roman emperor, philosopher)</cite>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most effective techniques to improve logic, reasoning and overall decision-making for most LLMs is to use \"Chain of Thought\" (CoT) techniques. The \"Chain of Thought\" approach helps by breaking down complex tasks into smaller steps, making it easier to solve problems without missing important details. It improves accuracy because each step is made clear to the LLM and helps avoid mistakes. This method also makes the thought process easier to understand and explain, allowing for easier corrections when something goes wrong. The approach is useful for handling difficult concepts and multi-step problems like math or logic, making things clearer and more manageable.\n",
    "\n",
    "The name of the \"Chain of Thought\" technique has been recently popularized by Generative AI. However, this technique is not new nor is it specific only to Generative AI models. Breaking down complex tasks into simpler more approachable steps and organizing thoughts has been used by decision-makers, professional services organizations and management consulting companies for quite some time. Prior to Generative AI, the concepts have been known as: \"structured thinking\", \"MECE framework\" (Mutually Exclusive, Collectively Exhaustive), and \"hypothesis-driven problem-solving\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, approach the problem with a simple Decision prompt technique. The system decisoin prompt will be set to basic & clear decision assistant persona instructions. While this decision prompt is simple, it is still quite effective to instruct the LLM model on how to approach the decision problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Step | Left Bank Contents                 | Right Bank Contents | Action |\n",
       "|------|-------------------------------------|----------------------|--------|\n",
       "| 1    | Farmer, Wolf, Goat, Cabbage         | -                    | Farmer takes Goat to right bank |\n",
       "| 2    | Farmer, Wolf, Cabbage               | Goat                 | Farmer returns alone to left bank |\n",
       "| 3    | Farmer, Wolf, Cabbage               | Goat                 | Farmer takes Wolf to right bank |\n",
       "| 4    | Goat, Farmer                        | Wolf                 | Farmer brings Goat back to left bank |\n",
       "| 5    | Farmer, Goat, Cabbage               | Wolf                 | Farmer takes Cabbage to right bank |\n",
       "| 6    | Goat, Farmer                        | Wolf, Cabbage        | Farmer returns alone to left bank |\n",
       "| 7    | Farmer, Goat                        | Wolf, Cabbage        | Farmer takes Goat to right bank |\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemDecisionPrompt = \"\"\"\n",
    "You are a decision intelligence assistant. \n",
    "Provide structured, logical, and comprehensive advice.\n",
    "\n",
    "Output Format Instructions:\n",
    "When generating Markdown, do not use any headings higher than ###. \n",
    "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
    "All top-level section headers should start at ### or lower. \n",
    "\n",
    "Format the response using only a Markdown table. Only return a Markdown table. \n",
    "Do not enclose the table in triple backticks.\n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var puzzlePrompt = \"\"\"\n",
    "A farmer is on one side of a river with a wolf, a goat, and a cabbage. \n",
    "When he is crossing the river in a boat, he can only take one item with him at a time. \n",
    "The wolf will eat the goat if left alone together, and the goat will eat the cabbage if left alone together. \n",
    "How can the farmer transport the goat across the river without it being eaten?\n",
    "\"\"\";\n",
    "\n",
    "// Build Chat History with system prompt and the puzzle prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemDecisionPrompt);\n",
    "chatHistory.AddUserMessage(puzzlePrompt);\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "PromptExecutionSettings promptExecutionSettings = new();\n",
    "\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    // Create a new Azure OpenAI Prompt Execution settings object\n",
    "    #pragma warning disable SKEXP0010\n",
    "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
    "        SetNewMaxCompletionTokensEnabled = true,\n",
    "        MaxTokens = 1500,\n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0, \n",
    "        PresencePenalty = 0.0\n",
    "        };\n",
    "}\n",
    "else\n",
    "{\n",
    "    // Create a new OpenAI Prompt Execution settings object\n",
    "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0, \n",
    "        PresencePenalty = 0.0\n",
    "        };\n",
    "}\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var decisionResponse = await chatCompletionService.GetChatMessageContentAsync(chatHistory, promptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "decisionResponse.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's approach the same problem with a much more sophisticated \"Chain of Thought\" (CoT) system prompt to break the problem down and think about it more in depth. Notice that the prompt below is much more detailed in how the \"decision intelligence assistant\" should approach the problem, highlighting things it should or should not consider and the way it should arrive at the final answer. \n",
    "\n",
    "Chain of Thought (CoT) prompt instructions will vary depending on how the problem needs to be approached. It can include very specific decision framework instructions, systematic decision heuristics or management consulting best practices. In general, these detailed prompts result in the LLM providing more detail and usually better outcomes. However, there are a few drawbacks to overusing Chain of Thought (CoT):\n",
    "* A very long and detailed Chain of Thought (CoT) can confuse the LLM model, especially if the LLM model is smaller (i.e. GPT-4o-mini or Phi-4 etc.)\n",
    "* GenAI LLM models can hallucinate not just on output of answers. They can also hallucinate the Chain of Thought (CoT) they are describing in the final answer! This is a very sneaky way of potentially providing a confident answer paired with a confident approach (Chain of Thought) that the LLM may not even be using! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Step | Reasoning | Action |\n",
       "|------|-----------|--------|\n",
       "| 1 | The key constraint is avoiding situations where the wolf and goat are left together, or the goat and cabbage are left together when the farmer is absent. | Identify safe states and move items without violations. |\n",
       "| 2 | If the farmer first takes the goat across, the wolf and cabbage left together are fine (no eating). | Take the goat across first and leave it on the far side. |\n",
       "| 3 | The farmer returns alone to the original side to fetch another item. If he takes the wolf next, he must avoid leaving the wolf with goat. | Return alone. |\n",
       "| 4 | Taking the wolf next would leave it with the goat, so instead, take the wolf but then bring the goat back to avoid conflict. | Take wolf across; bring goat back. |\n",
       "| 5 | Now the goat is back, and the wolf is safe on the far side. The farmer can now take the cabbage across without danger (wolf and cabbage are fine together). | Take cabbage across and leave it with wolf. |\n",
       "| 6 | Finally, return alone to fetch the goat, and bring goat across to far side where wolf and cabbage are already safely together. | Bring goat across. |\n",
       "| 7 | Final arrangement: all three safely across with no conflict. | All done safely. |\n",
       "\n",
       "**Sequence of Moves:**\n",
       "1. Farmer takes Goat → Far Side  \n",
       "2. Farmer returns alone → Near Side  \n",
       "3. Farmer takes Wolf → Far Side  \n",
       "4. Farmer brings Goat back → Near Side  \n",
       "5. Farmer takes Cabbage → Far Side  \n",
       "6. Farmer returns alone → Near Side  \n",
       "7. Farmer takes Goat → Far Side  \n",
       "\n",
       "Would you like me to also **draw a diagram** of each stage for clarity?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemPromptChainOfThought = \"\"\"\n",
    "You are a Decision Intelligence assistant designed to think through problems step-by-step using Chain-of-Thought (CoT) prompting. \n",
    "Before providing any answer, you must: \n",
    "\n",
    "1) Understand the Problem: Carefully read and understand the user's question or request. \n",
    "\n",
    "2) Break Down the Reasoning Process: Outline the steps required to solve the problem or respond to the request logically and sequentially. Think aloud and describe each step in detail. \n",
    "Explain Each Step: Provide reasoning or calculations for each step, explaining how you arrive at each part of your answer. \n",
    "Provide structured, logical, and comprehensive advice. \n",
    "\n",
    "3) Review the Thought Process: Double-check the reasoning for errors or gaps before finalizing your response. \n",
    "Always aim to make your thought process transparent and logical.\n",
    "\n",
    "4) Arrive at the Final Answer: Only after completing all steps, provide the detailed final answer or detailed solution. \n",
    "\n",
    "5) Communicate the final decision details using the Minto Pyramid Principle. \n",
    "\n",
    "Output Format Instructions:\n",
    "When generating Markdown, do not use any headings higher than ###. \n",
    "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
    "All top-level section headers should start at ### or lower. \n",
    "\n",
    "Format the response using only a Markdown table. Only return a Markdown table. \n",
    "Do not enclose the table in triple backticks.\n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var puzzlePrompt = \"\"\"\n",
    "A farmer is on one side of a river with a wolf, a goat, and a cabbage. \n",
    "When he is crossing the river in a boat, he can only take one item with him at a time. \n",
    "The wolf will eat the goat if left alone together, and the goat will eat the cabbage if left alone together. \n",
    "How can the farmer transport the goat across the river without it being eaten?\n",
    "\"\"\";\n",
    "\n",
    "// Create a new chat history object using the new Chain of Thought system prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemPromptChainOfThought);\n",
    "chatHistory.AddUserMessage(puzzlePrompt);\n",
    "\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    // Create a new Azure OpenAI Prompt Execution settings object\n",
    "    #pragma warning disable SKEXP0010\n",
    "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
    "        SetNewMaxCompletionTokensEnabled = true,\n",
    "        MaxTokens = 1500,\n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0, \n",
    "        PresencePenalty = 0.0\n",
    "        };\n",
    "}\n",
    "else\n",
    "{\n",
    "    // Create a new OpenAI Prompt Execution settings object\n",
    "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0, \n",
    "        PresencePenalty = 0.0\n",
    "        };\n",
    "}\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var decisionResponseChainOfThought = await chatCompletionService.GetChatMessageContentAsync(chatHistory, promptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "decisionResponseChainOfThought.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Generative AI model has generated two different decision approaches to the same retirement decision question. An LLM can be used to decide which decision approach is of better quality. The evaluation could be done by another AI model or an AI model from different AI provider to reduce potential bias. \n",
    "\n",
    "After running the evaluation of the decision prompts below, notice the GenAI LLM model prefers the approach of the Chain of Thought (CoT) over the simple system prompt instruction. Furthermore, the AI model appreciates using the \"Decision Communication\" step with the applied Minto Pyramid.  \n",
    "\n",
    "> 📝 **Note:** When executing the decision approach evaluation below, you may notice that sometimes Approach 1 is preferred. This happens as Approach 2 with Chain of Thought is considered verbose and not a clear as Approach 1 to the AI model.  In a real-world implementation, the prompt instruction will have this made very clear on what the criteria are. I specifically left that instruction out of the prompt to illustrate that even an AI model can vary it's preference!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Decision Approaches Evaluation: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| Approach | Logical Structured Reasoning | Detail of Approach to Decision | Quality of Communication | Score |\n",
       "|----------|------------------------------|--------------------------------|--------------------------|-------|\n",
       "| Approach 1 | Presents a correct and sequential solution in a clear tabular form, but lacks upfront reasoning or explanation of why moves are chosen; logic is implied by the steps but not explicitly described. | Details all item locations for each step, which helps verify correctness; however, does not state rationale for each action or the constraints being addressed. | Table is concise and clear, but absence of reasoning limits accessibility for those unfamiliar with the puzzle logic. | 7 |\n",
       "| Approach 2 | Offers explicit logical reasoning and constraints before and during each step, making the thought process transparent; each choice is justified to avoid conflicts. | Provides full sequence of moves and explains the reasoning behind them, ensuring constraints are always respected; more comprehensive than Approach 1. | Communicates clearly with both a reasoning column and a summarized sequence of moves; verbose but accessible and educational; even offers optional diagrams for further clarity. | 9 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var systemPromptEvaluateResponses = \"\"\"\n",
    "You are an assistant that is evaluating an approach response to a question.\n",
    "You will be provided with an important decision as well as two proposed approaches.\n",
    "The two approaches are labeled \"Approach 1\" and \"Approach 2\".\n",
    "\n",
    "Compare the two approaches and evaluate them based on their: \n",
    "Logical structured reasoning of approach, detail of the approach to the decision and the quality the communication. \n",
    "\n",
    "Create a final score between 1 and 10 for each approach based on the evaluation criteria.\n",
    "\n",
    "Format the response using only a Markdown table. Only return a Markdown table. \n",
    "Do not enclose the table in triple backticks.\n",
    "\"\"\";\n",
    "\n",
    "var decisionEvaluationTemplateApproaches = $\"\"\"\n",
    "Decision Scenario: \n",
    "{puzzlePrompt}\n",
    "------------------------------------------------\n",
    "Approach 1: \n",
    "{decisionResponse.Content} \n",
    "End of Approach 1\n",
    "------------------------------------------------\n",
    "Approach 2: \n",
    "{decisionResponseChainOfThought.Content} \n",
    "End of Approach 2\n",
    "\"\"\";\n",
    "\n",
    "// Create a new chat history object using the new Chain of Thought system prompt\n",
    "var chatHistoryApproachEvaluation = new ChatHistory();\n",
    "chatHistoryApproachEvaluation.AddSystemMessage(systemPromptEvaluateResponses);\n",
    "chatHistoryApproachEvaluation.AddUserMessage(decisionEvaluationTemplateApproaches);\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    // Create a new Azure OpenAI Prompt Execution settings object\n",
    "    #pragma warning disable SKEXP0010\n",
    "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
    "        SetNewMaxCompletionTokensEnabled = true,\n",
    "        MaxTokens = 1500,\n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0, \n",
    "        PresencePenalty = 0.0\n",
    "        };\n",
    "}\n",
    "else\n",
    "{\n",
    "    // Create a new OpenAI Prompt Execution settings object\n",
    "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0, \n",
    "        PresencePenalty = 0.0\n",
    "        };\n",
    "}\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var evaluationResponseApproach1 = await chatCompletionService.GetChatMessageContentAsync(chatHistoryApproachEvaluation, promptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "\"### Decision Approaches Evaluation: \".DisplayAs(\"text/markdown\");\n",
    "evaluationResponseApproach1.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the output section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Understanding Collective Intelligence for Decision Intelligence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "#### Collective Intelligence - Pooling Wisdom of Multiple Opinions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📜 **_\"The four conditions that characterize wise crowds: diversity of opinion, independence, decentralization, and aggregation.\"_**\n",
    ">\n",
    "> -- <cite>James Surowiecki (American journalist, author of The Wisdom of Crowds, and former columnist for The New Yorker)</cite> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you’ve hurt your leg playing a long season of football games. You have another football season quickly approaching and you would like to understand how long will it take to heal properly. Additionally, you would like to understand the optimal medical treatment to ensure you are ready at the start of the next football season. You decide to visit three different doctors for their medical opinions. You don’t want to rely on just one doctor because each professional might notice something the others miss. Each medical specialist may decide to recommend a different approach based on their expertise or their own experience treating leg injuries. After you receive opinions from three different specialists, you think about their recommendations and then formulate a path forward (decision) for a treatment plan for your leg. The final treatment plan could be a result a variety of factors. For example, it could be simple and all three doctors could recommend 4-6 weeks rest. Clearly in that case there is a consensus with three different doctors on the treatment approach. What if the doctors diverge in their opinions? What if 2 of 3 doctors recommend rest and a third recommends an additional procedure on top of rest? What if all three doctors opinions totally diverge? Now you have to personally judge those doctor opinions collectively or potentially weight one doctor's opinion more significantly than others. This scenario illustrates a simplified version of collective intelligence, where pooling diverse expert opinions often leads to a more informed and balanced decision.\n",
    "\n",
    "The idea of multiple experts arriving at a cohesive conclusion isn’t new. It has been demonstated that pooling the wisdom of multiple “opinions” can often outperform a single prediction. Those opinions don't have to be human experts. The opinions can be outcomes from a statistical model, a large survey, a machine learning model or Generative AI. You have probably have heard the terms: Wisdom of the Crowds, Collective Intelligence, Bootstrapping (technique in statistical analysis), Ensembling (Machine Learing) or Mixture of Experts (Generative AI). These are all similar techniques (with their own unique implementations) that derive of the core concept of \"pooling wisdom of multiple opinions\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-SelfConsistency.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of \"Wisdom of the Crowds\" at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Wisdom of the Crowds\" can scale well beyond just a few doctor's opinions. In the examples below, note the number of samples collected for each situation is much greater than just a few doctors. In fact, the amount of samples collected can be in the hundreds and the Collective Intelligence power can hold true. \n",
    "\n",
    "**Francis Galton’s Ox-Weighing Experiment (1906)** \n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-CollectiveIntelligence-OxWeight.png\"> \n",
    "\n",
    "Sir Francis Galton, an English statistician, collected 787 guesses from fairgoers trying to estimate the weight of an ox. The average guess was 1,197 pounds, and the actual weight of the ox turned out to be 1,198 pounds. To Galton’s surprise, the average of these guesses (1,197 pounds) came remarkably close to the ox’s actual weight (1,198 pounds)—off by a single pound, or less than 0.1%. That level of accuracy was notable because the crowd was composed of a mixed audience: farmers with relevant experience, but also onlookers, tradespeople, and curious fairgoers with no particular expertise.\n",
    "\n",
    "**Modern “Jelly Bean Jar” Contests**\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"700px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/Scenarios/Scenario-CollectiveIntelligence-JellyBeans.png\">\n",
    "\n",
    "Many schools and charities run fundraisers where people pay to guess the number of jelly beans in a jar. It’s commonly observed that while individual guesses can be wildly off, the average of a sufficiently large group is typically within a small percentage (often under 5% error) of the true count. As an example, Michael Mauboussin ran an 2007 experiment where Mauboussin presented a jar of jelly beans to 73 Columbia Business School students. The students' guesses ranged from 250 to 4,100, with an average error of 62%. However, the group's average guess was 1,151, which represented only a 3% off the correct number. Only two students guessed better!\n",
    "\n",
    "The cool part of the “Jelly Bean Jar” experiment is that it is very approachable to run yourself. In fact, you can do this with Generative AI as well. \n",
    "\n",
    "A short (5 minute) YouTube video illustrates running this experiment with human opinions:  \n",
    "[![Jelly Bean Jar Experiment](https://img.youtube.com/vi/AuQdoAa2FUs/0.jpg)](https://www.youtube.com/watch?v=AuQdoAa2FUs)\n",
    "\n",
    "\n",
    "**Netflix Recommendation Algorithm Million Dollar Prize**\n",
    "\n",
    "In 2006, Netflix launched the million-dollar Netflix Prize competition, challenging participants to improve its movie recommendation algorithm (Cinematch) by at least 10 percent. Over three years, data scientists and researchers worldwide experimented with innovative approaches, culminating in 2009 when an ensemble team calling itself “BellKor’s Pragmatic Chaos” finally met the 10-percent threshold with 10.06%. This group had blended multiple models into a single “ensemble” algorithm that outperformed any single predictive approach. This demonstrated how synthesis of different predictions can be more powerful than one model alone. Although Netflix ultimately chose not to deploy the winning solution due to technical and privacy considerations, the competition is still regarded as a landmark moment in machine learning and collective problem-solving.  \n",
    "\n",
    "More information can be found here: https://en.wikipedia.org/wiki/Netflix_Prize \n",
    "\n",
    "**“Ask the Audience” on Who Wants to Be a Millionaire?**\n",
    "\n",
    "On the TV quiz show, contestants can use the “Ask the Audience” lifeline to poll the studio audience for the correct answer. Historical data shows that the audience collectively identifies the correct answer around 90% of the time, which is significantly more accurate than individual expert panels, or even the “Phone a Friend” lifeline.\n",
    "\n",
    "**The U.S. Navy’s Hunt for the Missing Submarine Scorpion (1968)**\n",
    "\n",
    "When the USS Scorpion, a nuclear-powered submarine, vanished in 1968, the Navy enlisted a broad range of specialists to harness their varied expertise and wisdom for a methodical search. By applying Bayesian statistical techniques to each person’s estimate of where the submarine might lie, they were able to synthesize these disparate perspectives into a single, remarkably accurate prediction. The team’s calculated guess put the submarine’s probable location just a few hundred yards from its actual resting place! This is a testament to the effectiveness of coalescing multiple expert viewpoints. This success with the USS Scorpion search later inspired more widespread use of Bayesian approaches for complex rescue and recovery operations, affirming the power of collective intelligence in high-stakes scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics Explains why Collective Intelligence Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to understand that Collective Intelligence mechanisms are rooted in several statistics principles. This allows you to set up Collective Intelligence parameters appropriately for decision situations. Furthermore, this allows you to perform math (quantitative analysis) in the Decision Intelligence Execution step. The key statistical principles of Collective Intelligence:  \n",
    "* **Average of Independent Predictions:** The average of many independent predictions, opinions or guesses will average itself out towards the true value. Each individual prediction can be assumed to have an error.  \n",
    "Therefore the formula is:  Prediction = True Value + Error.  \n",
    "As long as the errors are random, they will trend to cancel each other out on average. \n",
    "* **Law of Large Numbers:** The more guesses you have, the more the random errors balance out, reducing the overall variance of the collective guess. Mathematically, if you have a large number of independent predictions, the average guess converges on the True Value. \n",
    "* **Central Limit Theorem:** The distribution of preductions will tend toward a bell curve (a normal distribution) around the Predicted True Value. When you take the average (mean) of a large sample from a sample distribution like this, it will often fall near the true population distribution. This happens more often in real-life than statistics courses lead on.  \n",
    "\n",
    "Statistics explaining Collective Intelligence (Wisdom of the Crowds) is greatly simplfied and there are things to consider when attempting to replicate this experiment with real-world decision situations:  \n",
    "\n",
    "* **Bias Matters:** Collective Intelligence works best when individual biases do not all tilt in the same direction. For example, if you only poll basketball players about height-related predictions, it may introduce a huge bias towards larger height in a single direction. \n",
    "\n",
    "* **Independence:** The group’s diversity and independence of guesses are critical. A group of people trained in the same way or over-influenced by each other’s guesses might show correlated errors, undermining the benefit of aggregation.\n",
    "\n",
    "* **Meaningful Sample Size:** The sampling error shrinks as you collect more predictions (guesses). Assume you have 𝑁 amount of independent predictions. If each prediction's random error in guessing has a standard deviation of 𝜎, then the standard error of the mean guess drops by about a factor of $\\sqrt{𝑁}$. What does this mean? The more samples you add, the more reduction of the error you will notice. Furthermore, you will notice a larger reduction in error with the first initial predictions than further predictions made. Saying it another way. For example, if you have a certain error from 10 samples and you want to reduce that prediction error by half you need a total of 40 samples. Conversely, if you have 100 samples and you want to reduce that prediction error by half you need a total of 400 samples! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Implementing Collective Intelligence with Generative AI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collective Intelligence with AI Scenario Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will re-create the classic “guess the number of jelly beans” challenge, with a glass filled with Hershey’s Kisses. If you think about how these challenges are typically done, a human is presented a container (jar, glass, clear bucket) filled with candy. The human making the guess can look inside the container, inspect it, sometimes even hold the container and their visual senses can give it a sense of scale. \n",
    "\n",
    "In order to simulate this as best as possible for Artifical Intelligence (limited to only visual senses):\n",
    "* Multiple images will be used (5 in total) of the same glass filled with Hershey's kisses\n",
    "* The glass will be clear, so the main perspective of the contents are not obstructed \n",
    "* Each image will show a different perspective view of the glass containing the candy\n",
    "* Each image will include two key reference points a soda can and a glass bottle, which we can assume the AI knows via it's training data sets\n",
    "* Each image will include a single Hershey's Kisses as a scale reference point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5 images are shown below. Before scrolling down, can you guess the number of Hershey's Kisses?\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"200px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses1.jpg\">\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"200px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses2.jpg\">\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"200px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses3.jpg\">\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"200px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses4.jpg\">\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" width =\"200px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses5.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 Note: There are a total of 50 Hershey's Kisses in the glass. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Point Estimates with Artificial Intelligence  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement Collective Intelligence with Generative AI, the first step is to be able to perform a single estimate. The code section below will use AI to perform a single point estimate based off of a single image of the glass filled with Hershey's kisses.\n",
    "\n",
    "The code should be familiar by now. The main change is that we are adding a reference to the actual Hershey's Kisses image. This will provide the \"eyes\" to the Artificial Intelligence model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "AI Estimate of Hershey's Kisses in the glass - Using a Single Image: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemDecisionPrompt = \"\"\"\n",
    "You are an expert visual estimator.\n",
    "Provide structured, logical, and comprehensive advice.\n",
    "\n",
    "Output Format Instructions:\n",
    "ONLY return a single integer as the answer. \n",
    "Do not include any other text, reasoning or explanation.\n",
    "\n",
    "Example Expected Outputs (each line is a separate output):\n",
    "12\n",
    "100\n",
    "1234\n",
    "5443\n",
    "45\n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var collectiveIntelligencePrompt = \"\"\"\n",
    "You have an image of a glass with Hershey's Kisses chocolates.\n",
    "There is a soda can, soda bottle and a single hershey kiss outside provided for scale.\n",
    "\n",
    "Estimate the number of Hershey's Kisses in the glass. \n",
    "Think through the estimate clearly using all the available information in the image.\n",
    "\n",
    "Provide only a single number as the answer.\n",
    "\"\"\";\n",
    "\n",
    "// Uri of a single image of a Hershey's Kisses in a glass\n",
    "Uri githubImageUri1 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses1.jpg\");\n",
    "\n",
    "// Build Chat History with system prompt and the puzzle prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemDecisionPrompt);\n",
    "chatHistory.Add(\n",
    "    new() {\n",
    "        Role = AuthorRole.User,\n",
    "        Items = [\n",
    "            new TextContent { Text = collectiveIntelligencePrompt },\n",
    "            new ImageContent { Uri = githubImageUri1 }\n",
    "        ]\n",
    "    });\n",
    "\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    // Create a new Azure OpenAI Prompt Execution settings object\n",
    "    #pragma warning disable SKEXP0010\n",
    "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
    "        SetNewMaxCompletionTokensEnabled = true,\n",
    "        MaxTokens = 5000,\n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0\n",
    "        };\n",
    "}\n",
    "else\n",
    "{\n",
    "    // Create a new OpenAI Prompt Execution settings object\n",
    "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0\n",
    "        };\n",
    "}\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var decisionResponse = await chatCompletionService.GetChatMessageContentAsync(chatHistory, promptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown\n",
    "(\"AI Estimate of Hershey's Kisses in the glass - Using a Single Image: \").DisplayAs(\"text/markdown\");\n",
    "decisionResponse.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single image only provides a small section of context to the AI system. It will would be more powerful to provide several different images to provide various perspectives angles. The idea is that the AI system can use these images to perform a better estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "AI Estimate of Hershey's Kisses in the glass - Using 5 images: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemDecisionPrompt = \"\"\"\n",
    "You are an expert visual estimator.\n",
    "Provide structured, logical, and comprehensive advice.\n",
    "\n",
    "Output Format Instructions:\n",
    "When generating Markdown, do not use any headings higher than ###. \n",
    "Avoid # and ## headers. Use only ###, ####, or lower-level headings if necessary. \n",
    "All top-level section headers should start at ### or lower. \n",
    "\"\"\";\n",
    "\n",
    "// Simple instruction prompt to plan retirement\n",
    "var collectiveIntelligencePromptMultipleImages = \"\"\"\n",
    "Estimate how many standard size Hershey's Kisses are inside a clear glass shown in five images.\n",
    "\n",
    "Reference objects for scale (present in every photo)\n",
    "- A 12 oz (355 ml) soda can\n",
    "- A 8 oz (237 ml) soda bottle\n",
    "- A single wrapped Hershey's Kiss placed outside the glass\n",
    "\n",
    "Estimate the number of Hershey's Kisses in the glass. \n",
    "Think through the estimate clearly using all 5 of the available information in all of the images.\n",
    "\n",
    "Provide only a single number as the answer.\n",
    "\"\"\";\n",
    "\n",
    "// Uris of a 5 images of a Hershey's Kisses in a glass\n",
    "Uri githubImageUri1 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses1.jpg\");\n",
    "Uri githubImageUri2 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses2.jpg\");\n",
    "Uri githubImageUri3 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses3.jpg\");\n",
    "Uri githubImageUri4 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses4.jpg\");\n",
    "Uri githubImageUri5 = new(\n",
    "    \"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses5.jpg\");\n",
    "\n",
    "\n",
    "// Build Chat History with system prompt and the puzzle prompt\n",
    "var chatHistory = new ChatHistory();\n",
    "chatHistory.AddSystemMessage(systemDecisionPrompt);\n",
    "chatHistory.Add(\n",
    "    new() {\n",
    "        Role = AuthorRole.User,\n",
    "        Items = [\n",
    "            // Provide 5 different images of the same glass with Hershey's Kisses chocolates\n",
    "            new TextContent { Text = collectiveIntelligencePromptMultipleImages },\n",
    "            new ImageContent { Uri = githubImageUri1 },\n",
    "            new ImageContent { Uri = githubImageUri2 },\n",
    "            new ImageContent { Uri = githubImageUri3 },\n",
    "            new ImageContent { Uri = githubImageUri4 },\n",
    "            new ImageContent { Uri = githubImageUri5 }\n",
    "        ]\n",
    "    });\n",
    "\n",
    "\n",
    "// Create a new OpenAI prompt execution settings object\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    // Create a new Azure OpenAI Prompt Execution settings object\n",
    "    #pragma warning disable SKEXP0010\n",
    "    promptExecutionSettings = new AzureOpenAIPromptExecutionSettings { \n",
    "        SetNewMaxCompletionTokensEnabled = true,\n",
    "        MaxTokens = 3500,\n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0\n",
    "        };\n",
    "}\n",
    "else\n",
    "{\n",
    "    // Create a new OpenAI Prompt Execution settings object\n",
    "    promptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "        // Uncomment if using a model that supports temperature, GPT-5 models do not support temperature (other than GPT-5-Chat)\n",
    "        // Temperature = 0.3,\n",
    "        TopP = 1.0, \n",
    "        FrequencyPenalty = 0.0\n",
    "        };\n",
    "}\n",
    "\n",
    "// Execute the chat completion request using the prompt and settings defined above\n",
    "var decisionResponse = await chatCompletionService.GetChatMessageContentAsync(chatHistory, promptExecutionSettings);\n",
    "// Display the result of the chat completion request as Markdown \n",
    "(\"AI Estimate of Hershey's Kisses in the glass - Using 5 images: \").DisplayAs(\"text/markdown\");\n",
    "decisionResponse.Content.DisplayAs(\"text/markdown\");\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding variance to simulate multiple independent estimates with Artifical Intelligence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-running the same AI configuration over a single image will not simulate different independent perspectives. Simulating different perspectives can be challenging, but it can be done by combining various configurations and images. Variance will be added to this Collective Intelligence scenario by \"crafting\" an AI system by randomly selecting these options:   \n",
    "* Two different AI models (GPT-4.1 and o4-mini) a \"General AI\" model and a \"Reasoning AI\" model\n",
    "* Three different instruction prompts (Simple, Detailed, Chain of Thought)\n",
    "* General AI Only: Three different Temeperature settings\n",
    "* Reasoning AI Only: Three different Reasoning Effort Settings\n",
    "* Using 3 random images from the 5 provided (10 different combinations)\n",
    "\n",
    "General AI and Reasoning AI support different prompt settings. The main way to add variance to a General OpenAI model is to use the temperature setting. Conversely, for a reasoning model the primary manner to add variance to a Reasoning OpenAI model is with reasoning effort. Therefore, depending on which AI model has been selected it will either vary temperature (Genral AI) or reasoning effort (Reasoning AI) not both. \n",
    "\n",
    "Each type of run (Reasoning AI or General AI) has: 3 * 3 * 10 = 90 varied ways it can be put together. Because, ther are two types of paths (Reasoning AI and General AI), there are a total of 180 (2 * 90) different combinations for this \"AI System\". That is quite a good amount of variance that can be introduced to estimate the amount of Hershey's Kisses in the glass.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.Net.Http;\n",
    "\n",
    "var httpClientAI = new HttpClient();\n",
    "httpClientAI.Timeout = TimeSpan.FromSeconds(300);\n",
    "\n",
    "// Example to build a Kernel with three different AI services\n",
    "var semanticKernel = Kernel.CreateBuilder()\n",
    "    .AddAzureOpenAIChatCompletion(\n",
    "        modelId: azureOpenAIModelDeploymentName,\n",
    "        deploymentName: azureOpenAIModelDeploymentName,\n",
    "        endpoint: azureOpenAIEndpoint,\n",
    "        apiKey: azureOpenAIAPIKey,\n",
    "        httpClient: httpClientAI,\n",
    "        serviceId: \"GeneralAI\")\n",
    "    .AddAzureOpenAIChatCompletion(\n",
    "        modelId: azureOpenAIReasoningModelDeploymentName,\n",
    "        deploymentName: azureOpenAIReasoningModelDeploymentName,\n",
    "        endpoint: azureOpenAIReasoningEndpoint,\n",
    "        apiKey: azureOpenAIReasoningAPIKey,\n",
    "        httpClient: httpClientAI,\n",
    "        serviceId: \"ReasoningAI\")\n",
    "    .Build();\n",
    "\n",
    "// Retrieve the chat completion service for each respective AI service (GeneralAI and ReasoningAI)\n",
    "var chatCompletionServiceGeneralAI = semanticKernel.GetRequiredService<IChatCompletionService>(\"GeneralAI\");\n",
    "var chatCompletionServiceReasoningAI = semanticKernel.GetRequiredService<IChatCompletionService>(\"ReasoningAI\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10: \n",
      "Collective Intelligence Prompt Number Chosen: 1\n",
      "AI Service Chosen: ReasoningAI\n",
      "Reasoning Effort Chosen: high\n",
      "Images Chosen: https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses3.jpg, https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses1.jpg, https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses5.jpg\n",
      "Raw response: 40\n",
      "Estimate: 40\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10: \n",
      "Collective Intelligence Prompt Number Chosen: 2\n",
      "AI Service Chosen: ReasoningAI\n",
      "Reasoning Effort Chosen: medium\n",
      "Images Chosen: https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses2.jpg, https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses5.jpg, https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses3.jpg\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Command cancelled.",
     "output_type": "error",
     "traceback": [
      "Command cancelled."
     ]
    }
   ],
   "source": [
    "// Set the system prompt to behave like a decision intelligence assistant (persona)\n",
    "var systemDecisionPrompt = \"\"\"\n",
    "You are an expert visual estimator.\n",
    "Provide structured, logical, and comprehensive advice.\n",
    "\n",
    "You are provided with several photographs of the **same** glass of Hershey's Kisses chocolates\n",
    "\n",
    "Reference objects for scale (present in every photo image)\n",
    "- A 12 oz soda can\n",
    "- A 8 oz soda bottle\n",
    "- A single wrapped Hershey's Kiss placed outside the glass\n",
    "\n",
    "Estimate the number of Hershey's Kisses in the glass. \n",
    "Think through the estimate clearly using all the available information in all of the images.\n",
    "\n",
    "Output Format Instructions:\n",
    "ONLY return a single integer as the answer. \n",
    "Do not include any other text, reasoning or explanation.\n",
    "\n",
    "Example Expected Outputs (each line is a separate output):\n",
    "12\n",
    "56\n",
    "1234\n",
    "5443\n",
    "30\n",
    "\"\"\";\n",
    "\n",
    "// Define Three different prompts for the same task\n",
    "var collectiveIntelligencePromptMultipleImagesSimple = \"\"\"\n",
    "Estimate how many Hershey's Kisses are in this glass from the images.\n",
    "\"\"\";\n",
    "\n",
    "var collectiveIntelligencePromptMultipleImagesDetailed = \"\"\"\n",
    "Examine perspective cues (external objects, table height, glass) and reason about the glass \n",
    "geometry (cylinder? rectangular prism?) to estimate volume and capacity.\n",
    "Estimate the number of Hershey's Kisses in the glass.\n",
    "\n",
    "Think clearly, but *only* return a single number.\n",
    "\"\"\";\n",
    "\n",
    "var collectiveIntelligencePromptMultipleImagesChainOfThought = \"\"\"\n",
    "First, think step-by-step about:\n",
    "1. Glass dimensions (height, diameter)\n",
    "2. Count number of Hershey's Kisses vertically from a single column\n",
    "3. Count number of Hershey's Kisses horizontally from a single row\n",
    "3. Expected total count: total number vertically * (2 * total number horizontally)\n",
    "\n",
    "Then, provide your final estimate of the number of Hershey's Kisses in the glass.\n",
    "\n",
    "Think silently, then give **one integer** answer on the last line.\n",
    "\"\"\";\n",
    "\n",
    "string[] collectiveIntelligencePrompts = new[]\n",
    "{\n",
    "    collectiveIntelligencePromptMultipleImagesSimple,\n",
    "    collectiveIntelligencePromptMultipleImagesDetailed,\n",
    "    collectiveIntelligencePromptMultipleImagesChainOfThought\n",
    "};\n",
    "\n",
    "// Define the different URI images of the glass with Hershey's Kisses chocolates\n",
    "Uri[] allImageUris =\n",
    "{\n",
    "    new Uri(\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses1.jpg\"),\n",
    "    new Uri(\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses2.jpg\"),\n",
    "    new Uri(\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses3.jpg\"),\n",
    "    new Uri(\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses4.jpg\"),\n",
    "    new Uri(\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/refs/heads/main/Images/CodeExercises/CollectiveIntelligence/HersheyKisses5.jpg\")\n",
    "};\n",
    "// Define three different temperature settings for the General AI service\n",
    "float[] topProbabilities = { 0.1f, 0.5f, 1.0f };\n",
    "// Define three different reasoning efforts for the Reasoning AI service\n",
    "string[] reasoningEfforts = { \"low\", \"medium\", \"high\" };\n",
    "// Define two different AI services\n",
    "string[] aiServices = { \"GeneralAI\", \"ReasoningAI\" };\n",
    "\n",
    "var aiEstimates = new List<int>();\n",
    "var numberOfIterations = 10; \n",
    "for (int i = 0; i != numberOfIterations; i++)\n",
    "{\n",
    "    Console.WriteLine($\"Iteration {i + 1} of {numberOfIterations}: \");\n",
    "\n",
    "    // Randomize the choice of collective intelligence prompt, AI service, temperature, reasoning effort, and selection of 3 images\n",
    "    var rng = new Random();\n",
    "    var collectiveIntelligencePromptInteger = rng.Next(collectiveIntelligencePrompts.Length);\n",
    "    string collectiveIntelligencePromptChosen     = collectiveIntelligencePrompts[collectiveIntelligencePromptInteger];\n",
    "    string aiServiceChosen     = aiServices[rng.Next(aiServices.Length)];\n",
    "    float  topPChosen       = topProbabilities[rng.Next(topProbabilities.Length)];\n",
    "    string reasoningChosen  = reasoningEfforts[rng.Next(reasoningEfforts.Length)];\n",
    "    var imagesChosen = allImageUris\n",
    "        .OrderBy(_ => rng.Next())\n",
    "        .Take(3)\n",
    "        .Select(uri => new ImageContent { Uri = uri })\n",
    "        .ToList();\n",
    "\n",
    "    Console.WriteLine($\"Collective Intelligence Prompt Number Chosen: {collectiveIntelligencePromptInteger+1}\");\n",
    "    Console.WriteLine($\"AI Service Chosen: {aiServiceChosen}\");\n",
    "    if (aiServiceChosen == \"ReasoningAI\")\n",
    "    {\n",
    "        Console.WriteLine($\"Reasoning Effort Chosen: {reasoningChosen}\");\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        Console.WriteLine($\"Top Chosen: {topPChosen}\");\n",
    "    }\n",
    "    Console.WriteLine($\"Images Chosen: {string.Join(\", \", imagesChosen.Select(i => i.Uri))}\");\n",
    "\n",
    "    // GeneralAI and ReasoningAI will have different PromptExecutionSettings\n",
    "    var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings();\n",
    "\n",
    "    if (aiServiceChosen == \"GeneralAI\")\n",
    "    {\n",
    "        openAIPromptExecutionSettings.TopP = topPChosen;\n",
    "    }\n",
    "    else if (aiServiceChosen == \"ReasoningAI\")\n",
    "    {\n",
    "        openAIPromptExecutionSettings.ReasoningEffort = reasoningChosen;\n",
    "    }\n",
    "\n",
    "    // Build Chat History with system prompt and the puzzle prompt\n",
    "    var chatHistory = new ChatHistory();\n",
    "    chatHistory.AddSystemMessage(systemDecisionPrompt);\n",
    "    chatHistory.Add(\n",
    "        new() {\n",
    "            Role = AuthorRole.User,\n",
    "            Items = [\n",
    "                new TextContent { Text = collectiveIntelligencePromptChosen },\n",
    "                new ImageContent { Uri = allImageUris[0] },\n",
    "                new ImageContent { Uri = allImageUris[1] },\n",
    "                new ImageContent { Uri = allImageUris[2] }\n",
    "            ]\n",
    "        });\n",
    "\n",
    "    var chatCompletionServiceToUse = semanticKernel.GetRequiredService<IChatCompletionService>(aiServiceChosen);\n",
    "    // Execute the chat completion request using the prompt and settings defined above\n",
    "    var decisionResponse = await chatCompletionServiceToUse.GetChatMessageContentAsync(chatHistory, openAIPromptExecutionSettings);\n",
    "    // Display the result of the chat completion request as Markdown\n",
    "    //decisionResponse.Content.DisplayAs(\"text/markdown\");\n",
    "\n",
    "\n",
    "    Console.WriteLine($\"Raw response: {decisionResponse.Content.ToString()}\");\n",
    "    var estimate = 0;\n",
    "    if (int.TryParse(decisionResponse.Content.ToString(), out estimate))\n",
    "    {\n",
    "        Console.WriteLine($\"Estimate: {estimate}\");\n",
    "        aiEstimates.Add(estimate);\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        Console.WriteLine(\"Failed to parse the estimate from the response.\");\n",
    "    }\n",
    "    (\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section\n",
    "}\n",
    "\n",
    "// Display the average estimate from all AI services\n",
    "if (aiEstimates.Count > 0)  \n",
    "{\n",
    "    var averageEstimate = aiEstimates.Average();\n",
    "    Console.WriteLine($\"Mininum estimate of Hershey's Kisses in glass: {aiEstimates.Min()}\");\n",
    "    Console.WriteLine($\"Maximum estimate of Hershey's Kisses in glass: {aiEstimates.Max()}\");\n",
    "    Console.WriteLine($\"Average estimate of Hershey's Kisses in glass: {averageEstimate}\");\n",
    "    Console.WriteLine($\"Actual number of Hershey's Kisses in glass: {50}\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"No estimates were generated.\");\n",
    "}\n",
    "(\"---\").DisplayAs(\"text/markdown\"); // Break of the ooutput section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the analysis show from the simulation of 10 runs above? The range is quite dramatic, with the lowest estimate on record 34 and the highest being 120. The average estimate is 56.9, which is pretty close to the actual count of 50 Hershey's Kisses in the glass. This translates to an average error of about 7 Hershey's Kisses or ~14%. Running the simulations at a much greater number or increasing the variance should lower that number even further.\n",
    "\n",
    "Another way to interpet the Collective Intelligence simulation is to look at individual results. For example, lets assume the \"AI System\" was not created and just a single run was performed. How well should you trust these results? Running the code below illustrates the difference between each individual AI estimate and the actual number of Hershey's Kisses in the glass. What should be facinating is that 9 times out of 10 an individual AI estimate has a higher difference than the \"collective average\" of the simulations. Therefore, in this example the Collective Intelligence of 10 independent AI estimates of Hershey's Kisses 90% of the time will provide a better estimate compared to a single AI estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Estimate: 36. Differenmce from actual: 14\n",
      "AI Estimate: 95. Differenmce from actual: 45\n",
      "AI Estimate: 34. Differenmce from actual: 16\n",
      "AI Estimate: 120. Differenmce from actual: 70\n",
      "AI Estimate: 56. Differenmce from actual: 6\n",
      "AI Estimate: 38. Differenmce from actual: 12\n",
      "AI Estimate: 38. Differenmce from actual: 12\n",
      "AI Estimate: 37. Differenmce from actual: 13\n",
      "AI Estimate: 35. Differenmce from actual: 15\n",
      "AI Estimate: 80. Differenmce from actual: 30\n",
      "Count of estimates greater than average distance from actual: 9 from 10\n"
     ]
    }
   ],
   "source": [
    "// Illustrate the difference between individual estimates and the actual number of Hershey's Kisses\n",
    "foreach (var estimate in aiEstimates)\n",
    "{\n",
    "    Console.WriteLine($\"AI Estimate: {estimate}. Differenmce from actual: {Math.Abs(estimate - 50)}\");\n",
    "}\n",
    "\n",
    "// Count of esimtates that are greater than the average distance from the actual number of Hershey's Kisses\n",
    "var countGreaterThanAverage = aiEstimates.Count(e => Math.Abs(e - 50) > Math.Abs(aiEstimates.Average() - 50));\n",
    "Console.WriteLine($\"Count of estimates greater than average distance from actual: {countGreaterThanAverage} from {aiEstimates.Count}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was very simple, but it showed that the \"Wisdom of the Crowds\" (Collective Intelligence) can be applied to Generative AI to improve estimates, reducing uncertainty and potentially providing better forecasts. This direct concept can be applied more advanced decisions simply by creating simulations that introduce proper variance in a complete AI system. \n",
    "\n",
    "Imagine that this system wasn't predicting the amount of Hershey's Kisses in a glass. Rather image the AI system was predicting sales of widgets in millions of dollars. Having an estimate between 36 million or 110 million has huge variance and implications. AI systems that do not have perfect information (can't see all of the Hershey's Kisses to just count them) will provide quite varied point estimates that have minimal value. Collective Intelligence techniques demonstrate the ability to converge to a \"true\" estimate range. This module proved that these techniques clearly apply to AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
