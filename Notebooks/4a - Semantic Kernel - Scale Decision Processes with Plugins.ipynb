{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;padding-right: 10px\" width =\"40px\" src=\"https://raw.githubusercontent.com/bartczernicki/DecisionIntelligence.GenAI.Workshop/main/Images/SemanticKernelLogo.png\">\n",
    "\n",
    "## Semantic Kernel - Scale Decision Processes with Plugins  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Intelligence applied in this module:  \n",
    "* Adding current knowledge (internet) to gather intelligence for more informed decisions  \n",
    "* Decision Scenario: Investigate a specific decision made after the recent NBA sports season.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Kernel Plugins are complete building blocks of functionality for AI orchestration. Plugins consist of multiple single responsibility functions (semantic or native). A plugin brings together all of the tools it needs a GenAI model, agent or assistant to use under a single construct. Below is an image of a Writer Plugin that consists of multiple functions: Brainstorming, E-mail generation, Translation etc. \n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"https://learn.microsoft.com/en-us/semantic-kernel/media/writer-plugin-example.png\">\n",
    "\n",
    "\n",
    "Plugins are very powerful because they allow an AI architect to compose functionality from many smaller functions. Plugins can be crafted in several different ways:\n",
    "* Use multiple native functions (C# methods) \n",
    "* Use multiple semantic functions exposed in prompt files, YAML configurations etc.  \n",
    "* Hybrid combinations of multiple native or semantic functions  \n",
    "* Remote API services called via functions (database, internet knowledge graph, APIs)  \n",
    "* Remote platform services (calling Azure Logic Apps, which includes over 1,400 connectors)  \n",
    "\n",
    "Learn more about Semantic Kernel Plugins: https://learn.microsoft.com/en-us/semantic-kernel/agents/plugins/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Initialize Configuration Builder & Build the Semantic Kernel Orchestration\n",
    "\n",
    "Execute the next two cells to:\n",
    "* Use the Configuration Builder to load the API secrets\n",
    "* Use the API configuration to build the Semantic Kernel orchestrator\n",
    "* The configuration builder will retrieve the Bing Search API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Bing.Search.WebSearch, 1.0.0</span></li><li><span>Microsoft.Extensions.Configuration, 9.0.0</span></li><li><span>Microsoft.Extensions.Configuration.Json, 9.0.0</span></li><li><span>Microsoft.SemanticKernel, 1.38.0</span></li><li><span>Microsoft.SemanticKernel.Plugins.Core, 1.38.0-alpha</span></li><li><span>Microsoft.SemanticKernel.Plugins.Web, 1.38.0-alpha</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.Extensions.Configuration, 9.0.0\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 9.0.0\"\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.38\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Plugins.Core, 1.38-alpha\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Plugins.Web, 1.38-alpha\"\n",
    "#r \"nuget: Microsoft.Bing.Search.WebSearch, 1.0.0\"\n",
    "\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "using System.IO;\n",
    "\n",
    "var configurationBuilder = new ConfigurationBuilder()\n",
    "    .SetBasePath(Directory.GetCurrentDirectory())\n",
    "    .AddJsonFile(\"local.settings.json\", optional: true, reloadOnChange: true)\n",
    "    .AddJsonFile(\"secrets.settings.json\", optional: true, reloadOnChange: true);\n",
    "var config = configurationBuilder.Build();\n",
    "\n",
    "// IMPORTANT: You ONLY NEED either Azure OpenAI or OpenAI connectiopn info, not both.\n",
    "// Azure OpenAI Connection Info\n",
    "var azureOpenAIEndpoint = config[\"AzureOpenAI:Endpoint\"];\n",
    "var azureOpenAIAPIKey = config[\"AzureOpenAI:APIKey\"];\n",
    "var azureOpenAIModelDeploymentName = config[\"AzureOpenAI:ModelDeploymentName\"];\n",
    "var bingSearchAPIKey = config[\"BingSearch:APIKey\"];\n",
    "// OpenAI Connection Info \n",
    "var openAIAPIKey = config[\"OpenAI:APIKey\"];\n",
    "var openAIModelId = config[\"OpenAI:ModelId\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI Service\r\n"
     ]
    }
   ],
   "source": [
    "Kernel semanticKernel;\n",
    "\n",
    "// Set the flag to use Azure OpenAI or OpenAI. False to use OpenAI, True to use Azure OpenAI\n",
    "var useAzureOpenAI = true;\n",
    "\n",
    "// Create a new Semantic Kernel instance\n",
    "if (useAzureOpenAI)\n",
    "{\n",
    "    Console.WriteLine(\"Using Azure OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddAzureOpenAIChatCompletion(\n",
    "            deploymentName: azureOpenAIModelDeploymentName,\n",
    "            endpoint: azureOpenAIEndpoint,\n",
    "            apiKey: azureOpenAIAPIKey)\n",
    "        .Build();\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"Using OpenAI Service\");\n",
    "    semanticKernel = Kernel.CreateBuilder()\n",
    "        .AddOpenAIChatCompletion(\n",
    "            modelId: openAIModelId,\n",
    "            apiKey: openAIAPIKey)\n",
    "        .Build();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Limitations of Current Knowledge of LLMs \n",
    "\n",
    "Decisions are being made in our environment and by own selves non-stop. In order to investigate and analyze current decisions, GenAI LLMs need current access to the knowledge graphs that persist this information. **In decision-making, this phase is called \"Gathering Relevant Intelligence\"** \n",
    "\n",
    "Execute the cell below to attempt to investigate what coaching decision did the Phoenix Suns make after the 2024 NBA playoffs?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot provide information about events or decisions made in September 2024, as my knowledge only extends up to October 2023."
     ]
    }
   ],
   "source": [
    "// Prompt Template for Decision Iquiry\n",
    "var promptTemplateString = \"\"\"\n",
    "What decision did {{$companyName}} make in September 2024?\n",
    "Only answer if you know the answer. Do not halliucinate.\n",
    "\"\"\";\n",
    "\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 2000, \n",
    "    Temperature = 0.1, \n",
    "    TopP = 1.0, \n",
    "    FrequencyPenalty = 0.0, \n",
    "    PresencePenalty = 0.0\n",
    "};\n",
    "\n",
    "var kernelArguments = new KernelArguments(openAIPromptExecutionSettings)\n",
    "{\n",
    "    [\"companyName\"] = \"Intel\"\n",
    "};\n",
    "\n",
    "await foreach (var streamChunk in semanticKernel.InvokePromptStreamingAsync(promptTemplateString, kernelArguments))\n",
    "{\n",
    "   Console.Write(streamChunk);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Acessing Current Knowledge with a Bing Web Search Plugin\n",
    "\n",
    "In order to inspect current decisions being made, an LLM needs access to a knowledge graph (internet) that includes recent information and news. Conveniently Semantic Kernel includes a web plugin that exposes access to the Bing Search knowledge graph. This allows Semantic Kernel to gather relevant intelligence for the decision topic using Bing's internet indexes.  \n",
    "\n",
    "Execute the two cells below to create and import the Bing connector to Semantic Kernel instance. **Notice that just by adding the Bing plugin, the link between Semantic Kernel knowledge and the LLM is still not made.**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Plugins.Web;\n",
    "using Microsoft.SemanticKernel.Plugins.Web.Bing;\n",
    "\n",
    "#pragma warning disable SKEXP0050\n",
    "var bingConnector = new BingConnector(bingSearchAPIKey);\n",
    "var bingSearchPlugin = new WebSearchEnginePlugin(bingConnector);\n",
    "\n",
    "semanticKernel.ImportPluginFromObject(bingSearchPlugin, \"bing\");\n",
    "#pragma warning restore SKEXP0050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot provide information about events or decisions made in September 2024, as my knowledge only extends up to October 2023."
     ]
    }
   ],
   "source": [
    "// Still doesn't work, even though Bing Knowledge Graph is enabled\n",
    "await foreach (var streamChunk in semanticKernel.InvokePromptStreamingAsync(promptTemplateString, kernelArguments))\n",
    "{\n",
    "   Console.Write(streamChunk);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Proving Semantic Kernel the ability to call the Bing Search Plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice after importing the Bing Search plugin into the Semantic Kernel instance, the LLM still was not able to answer the question. What is missing? **In addition to importing the appropriate plugin, the LLM needs to be \"allowed\" to automatically invoke imported Semantic Kernel functions. This is done by overriding the ToolCallBehavior property to AutoInvokeFunctions.**  \n",
    "\n",
    "Execute the cell below to allow auto invocation of Semantic Kernel functions. The configuration now allows Semantic Kernel to find the right tool (Bing Search) and automatically invoke it. Compare this output with the previous output(s), notice the GenAI LLM was able to answer the question.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In September 2024, Intel decided to postpone its annual Innovation event, which was originally scheduled for September 24-25, until 2025."
     ]
    }
   ],
   "source": [
    "// Prompt Template for Decision Iquiry\n",
    "var promptTemplateString = \"\"\"\n",
    "What decision did {{$companyName}} make in September 2024?\n",
    "Only answer if you know the answer. Do not halliucinate.\n",
    "\"\"\";\n",
    "\n",
    "// Try different settings (Temperature, FrequencyPenalty etc) to see how they affect the quality of the generated text\n",
    "var openAIPromptExecutionSettings = new OpenAIPromptExecutionSettings { \n",
    "    MaxTokens = 2000, \n",
    "    Temperature = 0.1, \n",
    "    TopP = 1.0, \n",
    "    FrequencyPenalty = 0.0, \n",
    "    PresencePenalty = 0.0,\n",
    "    // NEW: Enable Auto Invoking of Kernel Functions\n",
    "    // Allows it to call the available Bing Plugin\n",
    "    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions\n",
    "};\n",
    "\n",
    "var kernelArguments = new KernelArguments(openAIPromptExecutionSettings)\n",
    "{\n",
    "    [\"companyName\"] = \"Intel\"\n",
    "};\n",
    "\n",
    "// Now with Auto Invoking of Kernel Functions, let the magic happen\n",
    "await foreach (var streamChunk in semanticKernel.InvokePromptStreamingAsync(promptTemplateString, kernelArguments))\n",
    "{\n",
    "   Console.Write(streamChunk);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Understanding Auto Function Calling Behavior\n",
    "\n",
    "How does Semantic Kernel and the LLM know to call the function? What if there are multiple functions or plugins, how does LLM signal Semantic Kernel which function to call? \n",
    "\n",
    "Executing the cell below will illustrate that the invocation of the functions is not magic, but guided by the descriptions of the plugin function descriptions and parameter descriptions. Note that the Search function is described as \"Perform a Web Search\". This provides a big clue to Semantic Kernel that this a possible tool (function) to use to extract current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin: bing\n",
      "  Function Name: Search\n",
      "  Function Description: Perform a web search.\n",
      "    Function Parameters:\n",
      "      - query: Search query\n",
      "        default: ''\n",
      "      - count: Number of results\n",
      "        default: '10'\n",
      "      - offset: Number of results to skip\n",
      "        default: '0'\n",
      "\n",
      "Plugin: bing\n",
      "  Function Name: GetSearchResults\n",
      "  Function Description: Perform a web search and return complete results.\n",
      "    Function Parameters:\n",
      "      - query: Text to search for\n",
      "        default: ''\n",
      "      - count: Number of results\n",
      "        default: '1'\n",
      "      - offset: Number of results to skip\n",
      "        default: '0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Method for discovering the available functions loaded into Semantic Kernel via metadata\n",
    "private void PrintFunction(KernelFunctionMetadata func)\n",
    "{\n",
    "    Console.WriteLine($\"Plugin: {func.PluginName}\");\n",
    "    Console.WriteLine($\"  Function Name: {func.Name}\");\n",
    "    Console.WriteLine($\"  Function Description: {func.Description}\");\n",
    "\n",
    "    if (func.Parameters.Count > 0)\n",
    "    {\n",
    "        Console.WriteLine(\"    Function Parameters:\");\n",
    "        foreach (var p in func.Parameters)\n",
    "        {\n",
    "            Console.WriteLine($\"      - {p.Name}: {p.Description}\");\n",
    "            Console.WriteLine($\"        default: '{p.DefaultValue}'\");\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Console.WriteLine();\n",
    "}\n",
    "// Get the functions metadata\n",
    "var functions = semanticKernel.Plugins.GetFunctionsMetadata();\n",
    "\n",
    "foreach (KernelFunctionMetadata func in functions)\n",
    "{\n",
    "    PrintFunction(func);\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
